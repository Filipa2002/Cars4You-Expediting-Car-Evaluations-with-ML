{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "    .header-banner {\n",
    "        background-color: white;\n",
    "        color: black; \n",
    "        padding: 1rem; \n",
    "        font-family: 'Nunito', sans-serif;\n",
    "    }\n",
    "    .header-content {\n",
    "        max-width: 2000px;\n",
    "        margin: 0 auto;\n",
    "        display: flex;\n",
    "        align-items: center;\n",
    "        gap: 2rem;\n",
    "    }\n",
    "    .logo {\n",
    "        max-width: 160px;\n",
    "    }\n",
    "    .text-content {\n",
    "        flex: 1;\n",
    "    }\n",
    "    .text-content h1 {\n",
    "        font-size: 34px;\n",
    "        margin: 0 0 10px;\n",
    "        font-weight: 700;\n",
    "        color: #7e4d02ff;\n",
    "        border-bottom: 2px solid #e5c120ff;\n",
    "        padding-bottom: 10px;\n",
    "    }\n",
    "    .text-content h2 {\n",
    "        font-size: 21px;\n",
    "        margin: 0 0 5px;\n",
    "        font-weight: 600;\n",
    "        color: #222;\n",
    "    }\n",
    "    .member-list {\n",
    "        display: grid;\n",
    "        grid-template-columns: repeat(2, auto);\n",
    "        gap: 6px 40px;\n",
    "        font-size: 17px;\n",
    "        color: #444;\n",
    "    }\n",
    "    .member {\n",
    "        position: relative;\n",
    "        padding-left: 20px;\n",
    "    }\n",
    "</style>\n",
    "<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
    "<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Nunito:wght@400;700&display=swap\" rel=\"stylesheet\">\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<header class=\"header-banner\">\n",
    "    <div class=\"header-content\">\n",
    "        <img src=\"https://i.ibb.co/JBPWVYR/Logo-Nova-IMS-Black.png\" alt=\"NOVA IMS Logo\" class=\"logo\">\n",
    "        <div class=\"text-content\">\n",
    "            <h1>Cars 4 You: Expediting Car Evaluations with ML</h1>\n",
    "            <h2>Group 37</h2>\n",
    "            <div class=\"member-list\">\n",
    "                <div class=\"member\">Filipa Pereira, 20240509</div>\n",
    "                <div class=\"member\">Gonçalo Silva, 20250354</div>\n",
    "                <div class=\"member\">Marta La Feria, 20211051 </div>\n",
    "                <div class=\"member\">Tomás Coroa, 20250394 </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</header>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color:#f8f4ef; border-left:5px solid #d4b781ff; padding:12px 18px; border-radius:8px; font-family:sans-serif; font-size:14px; line-height:1.4; width: 720px;\">\n",
    "\n",
    "  <b style=\"color:#4b2e05;\"> Index</b>\n",
    "\n",
    "  <ol style=\"margin:8px 0 0 18px; padding:0;\">\n",
    "    <li style=\"color:#4b2e05;\">Identifying Business Needs</li>\n",
    "    <li style=\"color:#4b2e05;\">Data Exploration and Preprocessing\n",
    "      <ul style=\"margin:4px 0 4px 15px; list-style-type:circle;\">\n",
    "        ...\n",
    "        <li style=\"color:#4b2e05;\">2.11. Feature Selection</li>\n",
    "        <ul style=\"margin:3px 0 3px 15px; list-style-type:square;\">\n",
    "            <li style=\"color:#4b2e05;\">2.11.1. Filter Methods</li>\n",
    "            <li style=\"color:#4b2e05;\">2.11.2. Wrapper Methods</li>\n",
    "            <li style=\"color:#4b2e05;\">2.11.3. Embedded Methods</li>\n",
    "          </ul>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li style=\"color:#4b2e05;\">Regression Benchmarking</li>\n",
    "    <ul style=\"margin:4px 0 4px 15px; list-style-type:circle;\">\n",
    "        <li style=\"color:#4b2e05;\">3.1.Regression Benchmarking</li>\n",
    "        <li style=\"color:#4b2e05;\">3.2. APAGAR</li>\n",
    "    </ul>\n",
    "    <li style=\"color:#4b2e05;\">Open-Ended Section</li>\n",
    "    \n",
    "  </ol>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APAGAR\n",
    "# 2. WRAPPER METHODS\n",
    "# 2.1 TENHO RFE COM LR E COM RANDOMFOREST REGRESSOR\n",
    "# 2.2. QUERO APROVEITAR E FAZER PLOT AQUI DESTE TIPO TANTO NO CASO LR QUANTO RANDOMFOREST:\n",
    "# plt.plot(list(range(1,8)), train_score_list, label=\"Score on Training Set\", color='yellowgreen')\n",
    "# plt.plot(list(range(1,8)), val_score_list, label=\"Score on Validation Set\", color='dimgray')\n",
    "# plt.xlabel(\"Number of features\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# Não queremos ser nós a decidir o nr de features a escolher, deixamos o modelo decidir por nós\n",
    "# ranking_, support_\n",
    "\n",
    "\n",
    "\n",
    "# 3. EMBEDDING METHODS\n",
    "# 3.1. LASSO E TAMBÉM RIDGE\n",
    "\n",
    "# AQUI APLICAR ESTE PLOT EM VEZ DE IMPRIMIR OS VALORES DO COEF\n",
    "# def plot_importance(coef,name):\n",
    "#     imp_coef = coef.sort_values()\n",
    "#     plt.figure(figsize=(8,10))\n",
    "#     imp_coef.plot(kind = \"barh\")\n",
    "#     plt.title(\"Feature importance using \" + name + \" Model\")\n",
    "#     plt.show()\n",
    "\n",
    "# 3.2. QUERO TAMBÉM USAR - **Tree-based methods**: These methods use decision trees to calculate feature importance based on how much each feature contributes to reducing the impurity of the tree. Examples include Random Forest and Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APAGAR: VER SE SÓ AQUI ESTÃO OS IMPORT E AQUELES NECESSÁRIO\n",
    "\n",
    "# Standard library\n",
    "from itertools import combinations\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # Statistics                                   APAGAR: TEMOS DE USAR AS SUAS VERSÕES EM SKLEARN PARA FUNCIONAR COMO QUEREMOS\n",
    "# from scipy import stats\n",
    "# from scipy.optimize import minimize\n",
    "# from scipy.stats import ttest_ind, chi2_contingency, f_oneway\n",
    "\n",
    "# Sklearn - Base\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Sklearn - Feature Selection\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold, f_classif, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# Sklearn - Models\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, \n",
    "    ExtraTreesRegressor, \n",
    "    GradientBoostingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Sklearn - Metrics\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, \n",
    "    root_mean_squared_error, \n",
    "    mean_pinball_loss, \n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "# Custom utilities\n",
    "import utils\n",
    "\n",
    "# MLxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "\n",
    "# Plot style (APAGAR maybe)\n",
    "palette = ['#5C4212','#a92f02', '#a55b1bf9', '#b08972', '#e3a76c', '#e5c120','#f39c06','#f2e209']\n",
    "\n",
    "from IPython.display import display, HTML #NOVO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 60,768 rows, 37 features\n",
      "Val:   15,193 rows\n",
      "Test:  32,567 rows\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets (train, validation, test)\n",
    "X_train_scaled = pd.read_parquet(\"./project_data/X_train_scaled.parquet\", engine=\"pyarrow\")\n",
    "X_val_scaled   = pd.read_parquet(\"./project_data/X_val_scaled.parquet\",   engine=\"pyarrow\")\n",
    "X_test_scaled  = pd.read_parquet(\"./project_data/X_test_scaled.parquet\",  engine=\"pyarrow\")\n",
    "\n",
    "y_train = pd.read_parquet(\"./project_data/y_train.parquet\", engine=\"pyarrow\").squeeze(\"columns\")\n",
    "y_val   = pd.read_parquet(\"./project_data/y_val.parquet\",   engine=\"pyarrow\").squeeze(\"columns\")\n",
    "\n",
    "# Set carID as index\n",
    "X_train_scaled, X_val_scaled, X_test_scaled = [d.set_index('carID') for d in (X_train_scaled, X_val_scaled, X_test_scaled)]\n",
    "y_train, y_val = [d.set_index('carID') for d in (y_train, y_val)]\n",
    "\n",
    "print(f\"Train: {X_train_scaled.shape[0]:,} rows, {X_train_scaled.shape[1]} features\")\n",
    "print(f\"Val:   {X_val_scaled.shape[0]:,} rows\")\n",
    "print(f\"Test:  {X_test_scaled.shape[0]:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 60,768\n",
      "Val samples:   15,193\n"
     ]
    }
   ],
   "source": [
    "# Target arrays\n",
    "y_train_array = y_train['price'].values if isinstance(y_train, pd.DataFrame) else y_train.values.ravel()\n",
    "y_val_array   = y_val['price'].values if isinstance(y_val, pd.DataFrame) else y_val.values.ravel()\n",
    "\n",
    "# Log transformation of target (just like we mentioned on part1)\n",
    "y_train_log = np.log1p(y_train_array)\n",
    "y_val_log   = np.log1p(y_val_array)\n",
    "\n",
    "# Combined train+val for final model training\n",
    "# X_train_full_scaled   = pd.concat([X_train_scaled, X_val_scaled], axis=0) APAGAR\n",
    "#y_train_full_array    = np.concatenate([y_train_array, y_val_array]) APAGAR\n",
    "#y_train_full_log      = np.concatenate([y_train_log, y_val_log]) APAGAR\n",
    "\n",
    "print(f\"Train samples: {len(y_train_array):,}\")\n",
    "print(f\"Val samples:   {len(y_val_array):,}\")\n",
    "#print(f\"Full samples:  {len(y_train_full_array):,}\") APAGAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#644712c5; padding:15px; border-radius:10px; \n",
    "            box-shadow: 0px 4px 12px #644712c5;\">\n",
    "    <h1 style=\"margin:0; color:white; font-family:sans-serif; font-size:24px;\">\n",
    "         <span style=\"color: rgba(242, 226, 9, 1);\"><b>2.11 | Feature Selection</b></span>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #APAGAR\n",
    "# Explicar a importância de usar vários métodos de feature selection para não sermos bias (escrevi isso numa aula prática)\n",
    "\n",
    "# explicar que a nossa abordagem é mista porque por um lado temos muitas variáveis então queremo-nos livrar-nos o mais rápido possível de algumas delas (nas que acreditamos mesmo que não tenham relevância) mas depois deixar os outros métodos mais complexos (wrapper e embedded) fazerem o trabalho mais fino de selecionar as features mais relevantes de forma a não tirar logo e fazer uma seleção combinada \n",
    "\n",
    "# A Feature Selection (FS) é um processo hierárquico. A nossa estratégia será:\n",
    "# **1.** Low Variance Filter: Remover todas as features com variância $\\mathbf{\\le 0.01}$.Remova features quase constantes que não conseguem separar amostras.\n",
    "# Ação 1: Remoção por Baixa Variância (Implementado)Variáveis Removidas: hasDamage, transmission_other, fuelType_electric, fuelType_other.Justificativa: Estas features têm variância $\\le 0.01$ (e $0.00$ para hasDamage e transmission_other), o que indica que são quase constantes no dataset. São irrelevantes e adicionam ruído.\n",
    "# todas as variáveis com variância abaixo 0.01 foram imediatamente removidas\n",
    "# hasDamage: 0.0000\n",
    "# transmission_other: 0.0000\n",
    "# fuelType_electric: 0.0001\n",
    "# fuelType_other:\n",
    "\n",
    "\n",
    "# **2.** High Redundancy Filter --> Remover variáveis originais que são redundantes com features mais informativas (Target Encoded).Remover: Brand e brand_segment. (A informação de preço da marca está capturada em Brand_target_enc).\n",
    "# Ação 2: Remoção por Redundância MetodológicaVariáveis Removidas: Brand, brand_segment.Justificativa: Conforme o $\\mathbf{\\chi^2}$ indicou, estas features originais são redundantes. A sua informação de preço (segmento/média) está agora capturada de forma otimizada pelas features Target Encoded (Brand_target_enc). Removemos as originais para evitar multicolinearidade.\n",
    "\n",
    "\n",
    "# 3. Univariate Relevance Filter-->Usar *f_classif* e *mutual_info_regression* no X_{final} para pontuar a relevância de cada feature restante em relação ao $log(price)$.--> Identificar as features mais fracas (piores p-values/pontuações MI mais baixas) que não contribuem para a previsão.\n",
    "# C. Ação 3: Remoção por Baixa Relevância (Análise do MI Score)Analisamos o DataFrame feature_scores (em anexo), ordenado pelo $\\mathbf{MI\\_Score}$ (que mede a relevância de forma robusta):\n",
    "# mpg_per_liter            $0.6747$MUITO ALTO. Excelente feature de engenharia (Eficiência), a manter.\n",
    "# brand_model_target_enc   $0.6688$MUITO ALTO. A feature mais preditiva sobre o preço da marca/modelo.\n",
    "# transmission_manual\n",
    "\n",
    "\n",
    "# NOTA: LOGO NA 1A PARTE LIVRAMO-NOS DE PAINTQUALITY PORQUE NÃO SERIA POSSÍVEL OBTER ESSE DADO ANTES DA AVALIAÇÃO DO CARROE AINDA YEAR E MODEL PORQUE CRIAMOS VARIÁVEIS QUE SÃO DIRETAMENTE DERIVADAS DESTAS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e5c120ff; padding:15px; border-radius:10px;\">\n",
    "    <h1 style=\"margin:0; color:white; font-family:sans-serif; font-size:24px;\">\n",
    "         <span style=\"color: rgba(255, 255, 255, 1);\"><b>2.11.1 |  Filter Methods</b></span>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Variance Threshold**\n",
    "APAGAR\n",
    "O VarianceThreshold TESTE NÃO SUPERVISIONADO pode ser aplicado a qualquer variável numérica, independentemente da sua origem (seja contínua, binária ou codificada).\n",
    "calcula a variância empírica. Se a variância for muito baixa (indicando que a feature tem quase o mesmo valor em todas as amostras), é removida.\n",
    "Qualquer feature que apresente uma variância abaixo do limiar ($\\mathbf{\\text{threshold}}$) é considerada irrelevante para o modelo de previsão, independentemente da sua relação com o target ($\\mathbf{y}$). \n",
    "\n",
    "\n",
    "\n",
    "APAGAR: sklearn.chi2 É PARA ESQUECER PORQUE TARGET TERIA SER CATEGÓRICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get rid of variables with variance close to zero (<= 0.01)\n",
    "# vart = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "# #fit\n",
    "# vart.fit(X_train_scaled)\n",
    "\n",
    "# # boolean mask to identify low variance columns\n",
    "# low_variance_cols = X_train_scaled.columns[vart.variances_ <= 0.01]\n",
    "# print(\"Number of features with variance closer to zero:\", len(low_variance_cols))\n",
    "# print(\"Features with variance closer to zero:\")\n",
    "# for col in low_variance_cols:\n",
    "#     print(f\"{col}: {vart.variances_[X_train_scaled.columns.get_loc(col)]:.4f}\")\n",
    "\n",
    "# # Drop low variance columns from all DataFrames\n",
    "# for d in [X_train_scaled, X_val_scaled , X_test_scaled]:\n",
    "#     d.drop(columns=low_variance_cols, errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### **Mutual Information and $\\mathbf{\\chi^2}$ Test**\n",
    "# ##### **Statistical Hypothesis Testing**\n",
    "\n",
    "# Relevância Univariada \n",
    "# O MI é robusto mas lento. Usamos n_neighbors=5.\n",
    "\n",
    "# print(\"Pontuação MI: Maior valor = Mais Relevante (Melhor teste para o nosso Target)\")\n",
    "# print(\"ANOVA p-value: Baixo (< 0.05) = Relevante\")\n",
    "\n",
    "# $\\mathbf{mutual\\_info\\_regression}$\n",
    "#  é robusto e mede a dependência total entre as variáveis.\n",
    "#  mede a dependência entre $\\mathbf{X}$ e $\\mathbf{Y}$. Embora não teste a relação $\\mathbf{X_i}$ vs. $\\mathbf{X_j}$, é uma excelente métrica univariada de relevância que o ajuda a decidir o que manter.Regra: Se a feature A tem uma pontuação MI alta com o $\\mathbf{Y}$ e a feature B também tem uma pontuação MI alta, e sabe por domain knowledge que são dependentes, você mantém a que tiver a pontuação MI mais alta.\n",
    "#  O $\\mathbf{mutual\\_info\\_regression}$ mede o grau de dependência estatística entre a feature ($\\mathbf{X_i}$) e o target ($\\mathbf{y}$).Conceito: Procura a redução da incerteza sobre $\\mathbf{y}$ que é obtida ao conhecer $\\mathbf{X_i}$.\n",
    "#  $\\mathbf{mutual\\_info\\_regression}$ mede a dependência total (linear e não linear).AO CONTRÁRIO DO ANOVA $\\mathbf{f\\_classif}$ mede apenas a relação linear entre as médias.\n",
    "\n",
    "#  O $\\mathbf{mutual\\_info\\_regression}$ é o método da $\\mathbf{sklearn}$ que melhor lhe permite medir a importância das suas features (Target Encoded, OHE, etc.) para o $\\mathbf{\\log(price)}$ sem pressupostos de normalidade.\n",
    "\n",
    "#  Pontuação = 0: As features são totalmente independentes.\n",
    "\n",
    "# Pontuação Alta: As features são altamente dependentes (relevantes).\n",
    "\n",
    "# O $\\mathbf{mutual\\_info\\_regression}$ é ideal para o seu pipeline final ($\\mathbf{X}_{\\text{final}}$) porque é flexível e não paramétrico.\n",
    "\n",
    "# Tipo de Variável(X),            Pode ser Aplicado?,Pressupostos Específicos\n",
    "# 1.Variável Numérica (Contínua),         Sim. (Após PowerTransform).,\"Requer o parâmetro n_neighbors (vizinhos mais próximos) para estimar a densidade, que o seu código da sklearn já usa.\"\n",
    "# 2.Variável Binária (0/1),              Sim.,Deve usar o parâmetro discrete_features=True (ou a mask de colunas binárias) para que a função trate corretamente estas features discretas.\n",
    "# 3.Variável Categórica OHE,             Sim. (Tratada como binária).,Requer a definição de discrete_features=True.\n",
    "# 4.Variável Categórica Target Encoded,  Sim. (Tratada como contínua).,Não requer o parâmetro discrete_features.\n",
    "\n",
    "\n",
    "# Hipóteses para o $\\mathbf{mutual\\_info\\_regression}$O MI é um teste não paramétrico, o que é a sua maior vantagem:NÃO há pressupostos de Normalidade, Homogeneidade da Variância ou Relação Linear.Hipótese Nula ($H_0$): A feature ($\\mathbf{X_i}$) é independente da target ($\\mathbf{y}$).Você só precisa garantir que as suas variáveis contínuas são transformadas (PowerTransform) para melhorar a estabilidade e que as variáveis discretas (OHE/Flags) são sinalizadas corretamente usando o parâmetro discrete_features.\n",
    "\n",
    "\n",
    "# 1-Use os resultados do $\\mathbf{scipy.stats.chi2\\_contingency}$ (teste de redundância $\\mathbf{X_i}$ vs. $\\mathbf{X_j}$) para justificar o que remover (e.g., Brand, brand_segment).\n",
    "# 2- Use $\\mathbf{mutual\\_info\\_regression}$ no seu $\\mathbf{X_{\\text{final}}}$ para obter as pontuações de relevância de todas as features restantes e confirmar o que manter.\n",
    "\n",
    "# Isto significa que o $\\mathbf{mutual\\_info\\_regression}$ deve ser o seu padrão de referência (o teste principal), e o $\\mathbf{f\\_classif}$ (ANOVA) é apenas um auxiliar.\n",
    "\n",
    "\n",
    "# O $\\mathbf{f\\_classif}$ é bom para features binárias/OHE onde a relação é naturalmente linear (ou não existe). Para as suas features PowerTransformed e Target Encoded, onde as relações são complexas, o $\\mathbf{mutual\\_info\\_regression}$ fornece uma medida de relevância total e mais fiável para a sua Feature Selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA. $\\mathbf{f\\_classif}$\n",
    "# O f_classif aplica o Teste ANOVA (Análise de Variância) univariado para cada feature ($\\mathbf{X_i}$) em relação ao target ($\\mathbf{y}$).Propósito: Procura determinar se a separação da variável target ($\\mathbf{y}$) com base nos valores de uma determinada feature ($\\mathbf{X_i}$) resulta em diferenças de média estatisticamente significativas.\n",
    "# Estatística $F$ para cada feature\n",
    "\n",
    "# $F$ alto: Indica que a variância entre as médias dos grupos (ex: a média de preço dos carros manuais vs. automáticos) é muito maior do que a variância dentro desses grupos (o ruído). A feature é preditiva.\n",
    "\n",
    "# Ideal para testar a relevância de flags criadas (ex: is_new_car) ou colunas OHE.\n",
    "# PARA VARIÁVEIS: \n",
    "# - NÃO USAR PARA VAR NUMÉRICAS ( $\\mathbf{f\\_regression}$. é o teste t ou de correlação mais apropriado para features contínuas.)\n",
    "# - Variável Binária (0/1)\n",
    "# - Variáveis Categóricas OHE\n",
    "# - Variáveis Categóricas Target Encoded\tSim. (Tratadas como contínuas/discretas ordenadas).-> PODE NÃO SER O MELHOR PORQUE USOU A PRÓPRIA TARGET LOGO VAI ESTAR CORR. Target Encoded Feature ($\\mathbf{X}_{\\text{TE}}$): É altamente correlacionada com a média do $\\mathbf{y}$ para esse grupo.Teste $\\mathbf{f\\_classif}$: Testa a diferença nas médias de $\\mathbf{y}$ entre os grupos de $\\mathbf{X}_{\\text{TE}}$.O teste $\\mathbf{f\\_classif}$ sempre retornará um $p$-value muito baixo e um $F$ alto para uma feature Target Encoded, simplesmente porque a feature já é o próprio $\\mathbf{y}$ (com algum ruído de smoothing).ACABA POR SER UM TESTE REDUNDANTE. A feature é relevante por construção.\n",
    "\n",
    "# O f_classif (ANOVA) é um teste paramétrico e, embora a sklearn não verifique os pressupostos, eles devem ser mitigados para garantir a validade dos $p$-values:\n",
    "# 1. Normalidade do Target ($\\mathbf{y}$): O target ($\\mathbf{y}$) deve ser aproximadamente normal dentro de cada grupo.Sua Mitigação: Ao usar $\\mathbf{\\log(price)}$ como target (em vez do preço original enviesado), este pressuposto foi significativamente melhorado.\n",
    "\n",
    "# 2. Homogeneidade da Variância: A variância do target deve ser aproximadamente igual em todos os grupos.\n",
    "# Sua Mitigação: A transformação logarítmica ajuda a estabilizar a variância. Para verificar o que resta, você usaria o Teste de Levene na escala logarítmica.\n",
    "\n",
    "# 3. Amostras Independentes: Assumido (já que são carros individuais).\n",
    "# APAGAR\n",
    "# O $F$-statistic subestima a relevância total, porque a forte relação exponencial nos carros de luxo não é linear. Além disso, se a Normalidade residual for violada, o $p$-value é impreciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mask for feature types\n",
    "# # binary features\n",
    "# bin_variables = list(X_train_scaled.columns[X_train_scaled.nunique() == 2])\n",
    "\n",
    "# # target encoded features\n",
    "# te_variables = ['brand_mean_price', 'model_mean_price']\n",
    "\n",
    "# # continuous features (everything that is not binary)\n",
    "# continuous_features = [\n",
    "#     col for col in X_train_scaled.columns\n",
    "#     if col not in bin_variables\n",
    "# ]\n",
    "\n",
    "# #boolean mask for mutual_info_regression\n",
    "# discrete_mask = np.array([col in bin_variables for col in X_train_scaled.columns])\n",
    "\n",
    "# # 1. Mutual Information Regression (MI) - Non-Parametric Method (Main)\n",
    "# mi_scores = mutual_info_regression(\n",
    "#     X_train_scaled.values,\n",
    "#     y_train_log.ravel(),\n",
    "#     discrete_features=discrete_mask, \n",
    "#     n_neighbors=5,\n",
    "#     random_state=37,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # 2. f_classif (ANOVA) - Parametric Method (Auxiliary)\n",
    "# f_stats, f_p_values = f_classif(X_train_scaled.values, y_train_log.ravel())\n",
    "\n",
    "# # Compile Results into DataFrame\n",
    "# feature_scores = pd.DataFrame({\n",
    "#     'Feature': X_train_scaled.columns,\n",
    "#     'F_Score': f_stats.round(2),\n",
    "#     'ANOVA_p_value': f_p_values.round(4),\n",
    "#     'MI_Score': mi_scores.round(4)\n",
    "# })\n",
    "\n",
    "# # Show first low MI Score\n",
    "# feature_scores = feature_scores.sort_values(by='MI_Score', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# pd.set_option('display.max_rows',None)\n",
    "# display(feature_scores)\n",
    "# pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A decisão final de quais features remover deve ser uma combinação de evidência estatística (Pontuação MI) e justificação metodológica (Redundância e Domain Knowledge). A decisão de remoção baseia-se na irrelevância estatística (MI $\\approx 0$) e na falha paramétrica (ANOVA $p$-value alto).\n",
    "\n",
    "# 1. Fator de Decisão (O Limiar)O fator de decisão principal é o MI Score, que deve ser o seu limiar de relevância.Limiar Sugerido: Vamos definir o limiar de irrelevância como $\\mathbf{MI\\_Score \\le 0.002}$ (perto de zero). Isto inclui variáveis que são praticamente ruído.\n",
    "\n",
    "# Feature,MI Score,ANOVA p-value,Racional,Decisão\n",
    "# 0. previousOwners,0.0000,0.4119,MI =0. Totalmente irrelevante. O ANOVA não rejeita a independência (p>0.05).,REMOVER\n",
    "# 1. fuelType_unknown,0.0000,0.9904,MI =0. Irrelevante.,REMOVER\n",
    "# 2. year_is_missing,0.0005,0.9999,MI ≈0. Indica que o facto de year estar em falta não é preditivo para o preço.,REMOVER\n",
    "# 3. transmission_unknown,0.0011,0.8805,MI ≈0. Irrelevante.,REMOVER\n",
    "# 4. engineSize_is_missing,0.0013,1.0000,MI ≈0. Indica que a imputação foi bem-sucedida e a flag é ruído.,REMOVER\n",
    "# 5. tax_is_missing,0.0090,0.0000,\"MI baixo, mas não zero. ANOVA é significativo (p≈0). Indica que a informação de que tax está em falta é preditiva.\",MANTER\n",
    "# 6. fuelType_hybrid,0.0103,0.0000,\"MI baixo, mas significativo. Categoria rara, mas preditiva.\",MANTER\n",
    "# 7. mpg_is_missing,0.0116,0.0000,\"MI baixo, mas significativo. Flag MAR preditiva.\",MANTER\n",
    "\n",
    "# APAGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop irrelevant (MI Score ≈ 0) columns from all DataFrames\n",
    "# irrelevant= ['engineSize_is_missing', 'transmission_unknown', 'previousOwners', 'year_is_missing', 'fuelType_unknown'] \n",
    "\n",
    "# for d in [X_train_scaled, X_val_scaled, X_test_scaled]:\n",
    "#     d.drop(columns=irrelevant, errors='ignore', inplace=True)\n",
    "# print(f\"Removed irrelevant columns: {irrelevant}\")\n",
    "# print(f\"Number of features still present: {X_train_scaled.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Spearman Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste não paramétrico: É robusto a outliers e a distribuições não normais.\n",
    "# 1. Variável Numérica (Contínua)       Sim. (Ex: $\\mathbf{engineSize}$ vs. $\\mathbf{\\log(price)}$).A força da relação (o preço aumenta quando o motor aumenta, mesmo que a relação não seja perfeitamente reta).\n",
    "\n",
    "# 2. Variável Binária (0/1)           Sim. (Tratada como ordinal/discreta).A correlação de postos é menos informativa aqui do que o ANOVA ou o MI.\n",
    "# 3. Variável Target Encoded          Sim. (Tratada como ordinal).Mede a correlação entre a média de preço codificada e o $\\mathbf{\\log(price)}$ real.\n",
    "\n",
    "# Ambos são não paramétricos e robustos. O MI mede a dependência total (qualquer forma de relação), enquanto o Spearman mede apenas a dependência monótona (direção consistente). O MI é, teoricamente, uma medida de dependência mais completa.\n",
    "# O Spearman pode ser usado para complementar a Informação Mútua, especialmente para as features contínuas (após PowerTransform), para mostrar que a sua relação com o preço é forte e não linear.\n",
    "\n",
    "\n",
    "# A Correlação de Spearman é a ferramenta perfeita neste ponto do seu pipeline para analisar a redundância numérica entre todas as features e, simultaneamente, confirmar a relevância para o target $\\mathbf{\\log(price)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a Series for y_train_log with proper index\n",
    "# y_train_log_series = pd.Series(\n",
    "#     y_train_log, \n",
    "#     index=X_train_scaled.index, \n",
    "#     name='price_log'\n",
    "# )\n",
    "\n",
    "# ##### Spearman Correlation ####\n",
    "# # concatenate X_train_scaled and y_train_log_series\n",
    "# cor = pd.concat([X_train_scaled, y_train_log_series], axis=1).corr(method='spearman').round(2) #the method 'spearman' uses rank and handles all variable types in our set\n",
    "\n",
    "# TARGET_COL = 'price_log'\n",
    "# price_index = cor.columns.get_loc(TARGET_COL)\n",
    "\n",
    "# # Create custom annotation matrix for weak correlations\n",
    "# annot_matrix = np.full(cor.shape, \"\", dtype=object)\n",
    "# for i, col in enumerate(cor.index):\n",
    "#     corr_value = cor.loc[col, TARGET_COL]\n",
    "#     # Annotate only if |corr| < 0.1\n",
    "#     if abs(corr_value) < 0.1 and i != price_index:\n",
    "#         annot_matrix[price_index, i] = f\"{corr_value:.2f}\"\n",
    "        \n",
    "# # Create main annotation matrix for strong correlations\n",
    "# # Annotate only if |corr| >= 0.8\n",
    "# mask_annot_main = np.absolute(cor.values) >= 0.8\n",
    "# # Exclude 'price' row and column from this matrix\n",
    "# mask_annot_main[:, price_index] = False\n",
    "# mask_annot_main[price_index, :] = False\n",
    "# annot_main = np.where(mask_annot_main, cor.values.astype(str), \"\")\n",
    "\n",
    "# # Create the final annotation matrix by combining the two logics\n",
    "# final_annot_matrix = annot_main.copy()\n",
    "# for i in range(cor.shape[0]):\n",
    "#     for j in range(cor.shape[1]):\n",
    "#         # If the main annotation is empty and the weak one has a value, use the weak value\n",
    "#         if final_annot_matrix[i, j] == \"\" and annot_matrix[i, j] != \"\":\n",
    "#             final_annot_matrix[i, j] = annot_matrix[i, j]\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(16, 12))\n",
    "\n",
    "# # Create a custom diverging colormap based on orange tones\n",
    "# cmap = sns.diverging_palette(h_neg=30, h_pos=30, s=90, l=70, n=256, center=\"light\", as_cmap=True) \n",
    "\n",
    "# # Create a Mask to hide the upper triangle (to avoid redundancy)\n",
    "# mask = np.zeros_like(cor, dtype=np.bool_)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# sns.heatmap(\n",
    "#     data=cor,\n",
    "#     mask=mask,\n",
    "#     cmap=cmap,\n",
    "#     annot=final_annot_matrix, # combined annotation matrix\n",
    "#     fmt='s',                  # Format annotations as strings\n",
    "#     vmin=-1, vmax=1, center=0,# Ensure the scale is from -1 to 1, centered at 0\n",
    "#     linewidths=0.5,\n",
    "#     annot_kws={\"fontsize\": 9, \"color\": \"black\"},\n",
    "# )\n",
    "\n",
    "# plt.title('Spearman Correlation Matrix', fontsize=15, fontweight='bold')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Já tivemos a retirar algumas variáveis irrelevantes portanto o nosso foco aqui com Spearman é retirar variáveis redundantes\n",
    "# Vamos coemçar por retirar a variável que apresenta maior número de correlações muito fortes com outras variáveis (|corr| $\\geq 0.8$). que no caso é **'bran_segment_luxury'**. ou *brand_price_std* tiramos o primeiro que apresenta mais correlações muito fortes\n",
    "# de seguida várias têm muita corr com 2 variáveis, portanto começamos com a variável de 2 corr forte que apresenta a mais forte portanto retiramos\n",
    "# **age_mileage_interaction** vou retirar porque tem 2 corr fortes\n",
    "\n",
    "# **is_new_car**     **brand_mean_price** \n",
    "# Existem ainda variáveis que no máximo têm uma correlação muito forte com outra variável mas sabemos que por vezes essas variáveis são importantes para o modelo portanto não as retiramos já e deixamos os embedded methods escolher.\n",
    "# APAGAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #APAGAR: TIRAR DA PART1 A CRIAÇÃO DESTA VARIÁVEL\n",
    "# for d in [X_train_scaled, X_val_scaled, X_test_scaled]:\n",
    "#     d.drop(columns='age_squared', errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop redundant columns from all\n",
    "# redundant= ['brand_price_std', 'brand_segment_luxury', 'age_mileage_interaction'] \n",
    "# for d in [X_train, X_val , X_test]:\n",
    "#     d.drop(columns=redundant, errors='ignore', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ['mileage', 'tax', 'mpg', 'engineSize', 'brand_popularity',\n",
    "#        'model_popularity', 'age', 'miles_per_year',\n",
    "#        'premium_brand_engine_size_interaction', 'tax_per_engine',\n",
    "#        'mpg_per_liter', 'Brand_target_enc', 'brand_model_target_enc',\n",
    "#        'mpg_is_missing', 'tax_is_missing', 'is_new_car', 'is_old_car',\n",
    "#        'high_mileage', 'low_mileage', 'transmission_manual',\n",
    "#        'transmission_semi auto', 'fuelType_hybrid', 'fuelType_petrol',\n",
    "#        'brand_segment_mid_range'],\n",
    "\n",
    "\n",
    "# PODE SAIR: TAX, brand_price_std, age, miles_per_year, mpg_is_missing, tax_is_missing, 'is_new_car', 'is_old_car', 'high_mileage', 'low_mileage', transmission_semi auto, fuelType_hybrid, brand_segment_luxury, brand_segment_mid_range\n",
    "# TEM DE FICAR: mileage, MPG, engineSize, brand_popularity, model_popularity, Brand_target_enc, age_mileage_interaction, premium_brand_engine_size_interaction, tax_per_engine, mpg_per_liter, brand_model_target_enc, transmission_manual, fuelType_petrol\n",
    "# #SÓ FALTA  'age_squared', 'age_mileage_interaction' QUE REITIREI\n",
    "\n",
    "#APAGAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos só a considerar correlações fortes (|corr| $\\geq 0.8$) para identificar variáveis que sejam mesmo redundantes e não arriscar eliminar features que não traziam multicolinearidade e eram importantes para o modelo.\n",
    "APAGAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e5c120ff; padding:15px; border-radius:10px;\">\n",
    "    <h1 style=\"margin:0; color:white; font-family:sans-serif; font-size:24px;\">\n",
    "         <span style=\"color: rgba(255, 255, 255, 1);\"><b>2.11.2 |  Wrapper Methods</b></span>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APAGAR: Dizer que deixámos no notebook das experências RFE e também usámos no handout mas aqui decidimos ir por uma abordagem diferente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e5c120ff; padding:15px; border-radius:10px;\">\n",
    "    <h1 style=\"margin:0; color:white; font-family:sans-serif; font-size:24px;\">\n",
    "         <span style=\"color: rgba(255, 255, 255, 1);\"><b>2.11.3 |  Embedded Methods</b></span>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #APAGAR \n",
    "# O objetivo é evitar o bias de um único algoritmo.\n",
    "# O Meta-Ranking garante que apenas as features que todos os algoritmos (lineares e não lineares) concordam serem importantes chegam ao topo da lista ranked_features. Esta é a melhor forma de reduzir o bias de um único modelo na Feature Selection.\n",
    "# Se uma feature for consistentemente classificada como 1º, 2º, 1º, 2º, a soma será baixa.\n",
    "#     A lista final ranked_features é a ordenação por consenso, onde as features com a menor soma de ranks são consideradas as mais importantes por todo o conjunto de modelos.\n",
    "\n",
    "\n",
    "# Sim, os modelos LASSO e Elastic Net (e Ridge) são incluídos no Meta-Ranking de Importância, mesmo que já retirem variáveis sozinhos.\n",
    "\n",
    "# este for n_features in feature_range: pode ser visto como um wrapper method\n",
    "\n",
    "# O código começa com as 3 features mais importantes (n=3), treina e testa os 5 modelos (ElasticNet, ET, GB, RF, KNN) no conjunto de validação.Ele continua a adicionar a próxima feature mais importante da lista de consenso (n=4, n=5, etc.) e repete o treino e a validação.Objetivo: Otimizar o subset de features. O valor de $N$ que resultar no menor erro de validação (MAE) para cada modelo é o número ótimo de features para esse modelo.\n",
    "# O erro de validação (val_mae) permite encontrar o ponto de \"doce\" (sweet spot) onde o modelo tem a complexidade ideal, generalizando bem sem ser overfit ao ruído.\n",
    "\n",
    "# # diz-me uma coisa, quando faço feature importance, a importância tem de estar nos resultados obtidos para validation ne? não é para train, ou é?\n",
    "\n",
    "# tem uma componente wrapper na medida em que "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também há uma separação clara entre LASSO e ELASTICNET e os outros modelos Porque uma coisa é Feature Selection Regularization methods e outra é Tree-based methods (FEATURE IMPORTANCE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lasso Regularization (L1) \n",
    "# lasso_model = Lasso(random_state=37, max_iter=10000)\n",
    "# lasso_model.fit(X_train, y_train)\n",
    "# lasso_coefs = pd.Series(lasso_model.coef_, index=X_train.columns)\n",
    "# lasso_importance = lasso_coefs.abs().sort_values(ascending=False)\n",
    "\n",
    "# # Ridge Regularization (L2) \n",
    "# ridge_model = Ridge(random_state=37, max_iter=10000)\n",
    "# ridge_model.fit(X_train, y_train)\n",
    "# ridge_coefs = pd.Series(ridge_model.coef_, index=X_train.columns)\n",
    "# ridge_importance = ridge_coefs.abs().sort_values(ascending=False)\n",
    "\n",
    "# # ElasticNet Regularization (L1 + L2)\n",
    "# elasticnet_model = ElasticNet(l1_ratio=0.5, random_state=37, max_iter=10000)\n",
    "# elasticnet_model.fit(X_train, y_train)\n",
    "# elasticnet_coefs = pd.Series(elasticnet_model.coef_, index=X_train.columns)\n",
    "# elasticnet_importance = elasticnet_coefs.abs().sort_values(ascending=False)\n",
    "\n",
    "# # GB - Native Feature Importance\n",
    "# gb_base = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=37)\n",
    "# gb_base.fit(X_train, y_train)\n",
    "# gb_importance = pd.Series(gb_base.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# # RF - Native Feature Importance\n",
    "# rf_base = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=37, n_jobs=-1)\n",
    "# rf_base.fit(X_train, y_train)\n",
    "# rf_importance = pd.Series(rf_base.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# # ExtraTrees - Native Feature Importance\n",
    "# et_base = ExtraTreesRegressor(n_estimators=100, max_depth=10, random_state=37, n_jobs=-1)\n",
    "# et_base.fit(X_train, y_train)\n",
    "# et_importance = pd.Series(et_base.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# # # KNN - Mutual Information (captures non-linear relationships)\n",
    "# # mi_scores = mutual_info_regression(X_train, y_train, random_state=37)\n",
    "# # knn_importance = pd.Series(mi_scores, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# # Features eliminated by Lasso\n",
    "# lasso_eliminated = lasso_coefs[lasso_coefs == 0].index.tolist()\n",
    "# if lasso_eliminated:\n",
    "#     print(f\"\\n Features eliminated by Lasso: {lasso_eliminated}\")\n",
    "# else:\n",
    "#     print(f\"\\n Lasso kept all features\")\n",
    "\n",
    "# # Features eliminated by ElasticNet\n",
    "# elasticnet_eliminated = elasticnet_coefs[elasticnet_coefs == 0].index.tolist()\n",
    "# if elasticnet_eliminated:\n",
    "#     print(f\" Features eliminated by ElasticNet: {elasticnet_eliminated}\")\n",
    "# else:\n",
    "#     print(f\" ElasticNet kept all features\")\n",
    "\n",
    "# print(\"\\n Feature importance calculated for all 7 methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create ranks for each model (1 = most important)\n",
    "# elasticnet_ranks = pd.Series(range(1, len(elasticnet_importance) + 1), index=elasticnet_importance.index)\n",
    "# et_ranks = pd.Series(range(1, len(et_importance) + 1), index=et_importance.index)\n",
    "# gb_ranks = pd.Series(range(1, len(gb_importance) + 1), index=gb_importance.index)\n",
    "# rf_ranks = pd.Series(range(1, len(rf_importance) + 1), index=rf_importance.index)\n",
    "# knn_ranks = pd.Series(range(1, len(knn_importance) + 1), index=knn_importance.index)\n",
    "\n",
    "# # Combine and sort\n",
    "# feature_ranks = (elasticnet_ranks + et_ranks + gb_ranks + rf_ranks + knn_ranks).sort_values()\n",
    "\n",
    "# # Final sorted list\n",
    "# ranked_features = feature_ranks.index.tolist()\n",
    "# print(ranked_features)\n",
    "\n",
    "# # Model configurations\n",
    "# model_configs = {\n",
    "#     'ELASTICNET': lambda: ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=37, max_iter=10000),\n",
    "#     'ET': lambda: ExtraTreesRegressor(n_estimators=100, max_depth=10, random_state=37, n_jobs=-1),\n",
    "#     'GB': lambda: GradientBoostingRegressor(n_estimators=200, max_depth=7, learning_rate=0.06, random_state=37),\n",
    "#     'RF': lambda: RandomForestRegressor(n_estimators=100, max_depth=15, random_state=37, n_jobs=-1),\n",
    "#     'KNN': lambda: KNeighborsRegressor(n_neighbors=10, weights='distance', n_jobs=-1)\n",
    "# }\n",
    "\n",
    "# # Initialize results with history for plotting\n",
    "# best_results = {name: {'best_n': None, 'best_mae': float('inf'), 'features': ranked_features,\n",
    "#                        'train_history': [], 'val_history': []} \n",
    "#                 for name in model_configs.keys()}\n",
    "\n",
    "# # Test from 3 to all features\n",
    "# feature_range = range(3, len(ranked_features))\n",
    "\n",
    "# print(\"=\"*70)\n",
    "# print(\"FEATURE SELECTION - TESTING OPTIMAL NUMBER\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# for n_features in feature_range:\n",
    "#     features = ranked_features[:n_features]\n",
    "    \n",
    "#     for model_name, create_model in model_configs.items():\n",
    "#         model = create_model()\n",
    "#         model.fit(X_train[features], y_train)\n",
    "        \n",
    "#         # Calculate both train and val MAE\n",
    "#         train_mae = mean_absolute_error(y_train, model.predict(X_train[features]))\n",
    "#         val_mae = mean_absolute_error(y_val, model.predict(X_val[features]))\n",
    "        \n",
    "#         # Store history for plotting\n",
    "#         best_results[model_name]['train_history'].append(train_mae)\n",
    "#         best_results[model_name]['val_history'].append(val_mae)\n",
    "        \n",
    "#         # Update if improved\n",
    "#         if val_mae < best_results[model_name]['best_mae']:\n",
    "#             best_results[model_name]['best_mae'] = val_mae\n",
    "#             best_results[model_name]['best_n'] = n_features\n",
    "\n",
    "#     # Show progress\n",
    "#     print(f\"n={n_features:2d} | ElasticNet: {best_results['ELASTICNET']['val_history'][-1]:,.0f} | ExtraTrees: {best_results['ET']['val_history'][-1]:,.0f} | GB: {best_results['GB']['val_history'][-1]:,.0f} | RF: {best_results['RF']['val_history'][-1]:,.0f} | KNN: {best_results['KNN']['val_history'][-1]:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_features = ['model_mean_price',\n",
    "# 'engineSize',\n",
    "# 'age_mileage_interaction',\n",
    "# 'age_squared',\n",
    "# 'mpg',\n",
    "# 'mpg_per_liter',\n",
    "# 'transmission_manual',\n",
    "# 'premium_brand_engine_size_interaction',\n",
    "# 'model_popularity',\n",
    "# 'tax_per_engine',\n",
    "# 'mileage',\n",
    "# 'brand_mean_price',\n",
    "# 'brand_popularity',\n",
    "# 'brand_segment_mid_range',\n",
    "# 'fuelType_petrol',\n",
    "# 'transmission_semi auto']\n",
    "\n",
    "# final_features_sorted_rf = (\n",
    "#     rf_importance\n",
    "#     .loc[final_features]\n",
    "#     .sort_values(ascending=False)\n",
    "#     .index\n",
    "#     .tolist()\n",
    "# )\n",
    "\n",
    "\n",
    "# feature_range = range(3, len(final_features))\n",
    "\n",
    "# best_results ={}\n",
    "# # Initialize results with history for plotting\n",
    "# best_results = {name: {'best_n': None, 'best_mae': float('inf'), 'features': final_features_sorted_rf,\n",
    "#                        'train_history': [], 'val_history': []} \n",
    "#                 for name in model_configs.keys()}\n",
    "\n",
    "# print(\"=\"*70)\n",
    "# print(\"FEATURE SELECTION - TESTING OPTIMAL NUMBER\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# for n_features in feature_range:\n",
    "#     features = final_features_sorted_rf[:n_features]\n",
    "    \n",
    "#     for model_name, create_model in model_configs.items():\n",
    "#         model = create_model()\n",
    "#         model.fit(X_train[features], y_train)\n",
    "        \n",
    "#         # Calculate both train and val MAE\n",
    "#         train_mae = mean_absolute_error(y_train, model.predict(X_train[features]))\n",
    "#         val_mae = mean_absolute_error(y_val, model.predict(X_val[features]))\n",
    "        \n",
    "#         # Store history for plotting\n",
    "#         best_results[model_name]['train_history'].append(train_mae)\n",
    "#         best_results[model_name]['val_history'].append(val_mae)\n",
    "        \n",
    "#         # Update if improved\n",
    "#         if val_mae < best_results[model_name]['best_mae']:\n",
    "#             best_results[model_name]['best_mae'] = val_mae\n",
    "#             best_results[model_name]['best_n'] = n_features\n",
    "\n",
    "#  # Show progress\n",
    "#     print(f\"n={n_features:2d} | ElasticNet: {best_results['ELASTICNET']['val_history'][-1]:,.0f} | ExtraTrees: {best_results['ET']['val_history'][-1]:,.0f} | GB: {best_results['GB']['val_history'][-1]:,.0f} | RF: {best_results['RF']['val_history'][-1]:,.0f} | KNN: {best_results['KNN']['val_history'][-1]:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O principal motivo para usar o ExtraTreesRegressor para Feature Selection é a sua capacidade de fornecer uma pontuação de Importância da Característica (Feature Importance), baseada na métrica Gini Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop `paintQuality%`, `previousOwners`, `miles_per_year`, `transmission_semi auto`, `transmission_unknown`, `fuelType_hybrid`, `fuelType_petrol`, `fuelType_unknown`\n",
    "# X_train.drop(columns=['paintQuality%', 'previousOwners', 'miles_per_year', 'transmission_semi auto', 'transmission_unknown', 'fuelType_hybrid', 'fuelType_petrol', 'fuelType_unknown'], inplace=True)\n",
    "# X_val.drop(columns=['paintQuality%', 'previousOwners', 'miles_per_year', 'transmission_semi auto', 'transmission_unknown', 'fuelType_hybrid', 'fuelType_petrol', 'fuelType_unknown'], inplace=True)\n",
    "# X_test.drop(columns=['paintQuality%', 'previousOwners', 'miles_per_year', 'transmission_semi auto', 'transmission_unknown', 'fuelType_hybrid', 'fuelType_petrol', 'fuelType_unknown'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: #ffffff;\">3 | Regression Benchmarking</span>\n",
    "\n",
    "<div style=\"background-color:#e5c120ff; padding:15px; border-radius:10px; \n",
    "            box-shadow: 0px 4px 12px rgba(227, 167, 108, 1);\">\n",
    "    <h1 style=\"margin:0; color:white; font-family:sans-serif; font-size:24px;\">\n",
    "         <span style=\"color: #644712ff;\"><b>3 | Regression Benchmarking</b></span>\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"\n",
    "  border: 2px solid #42A5F5;\n",
    "  border-radius: 12px;\n",
    "  background-color: #E3F2FD;\n",
    "  padding: 14px;\n",
    "  font-family: 'Segoe UI', sans-serif;\n",
    "  color: #0D47A1;\n",
    "  box-shadow: 2px 2px 8px rgba(33, 150, 243, 0.15);\n",
    "\">\n",
    "  🚀 <b>O que é preciso:</b><br> \n",
    "\n",
    "- Explanation of model assessment **strategy** and **metrics** used\n",
    "- **Optimization** efforts: presentation, results and discussion\n",
    "- **Comparison** of performance between candidate models\n",
    " - Identify the type of problem and select the relevant algorithms.\n",
    " - Select one model assessment strategy to use throughout your work. Which metrics are you using to evaluate your model and why?\n",
    " - Train at least 1 model using the train dataset and obtain predictions for the test dataset.(Extra 1 point) Be on the Top-5 Best Groups in the Kaggle Competition\n",
    " - model assessment strategy (holdout, cross validation, etc...) and algorithms (minimum of 5 covered in class) used\n",
    " - rationale for choice of evaluation metric(s) and interpretation of results\n",
    "\n",
    "\n",
    "APAGAR\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APAGAR:\n",
    "\n",
    "\n",
    "Pinball Loss 0.25:\n",
    " ESTA É A IDEIA DO NEGÓCIO:\n",
    "O seu objetivo é: \"Prever valores abaixo do real do que acima\".Quando a previsão ($\\hat{y}$) é inferior ao valor real ($y$) $\\rightarrow$ o seu custo é mais baixo.Quando a previsão ($\\hat{y}$) é superior ao valor real ($y$) $\\rightarrow$ o seu custo é mais alto. No entanto, para a Cars 4 You, o erro mais crítico é quando se prevê demasiado alto ($\\hat{y} > y$) e acabam por pagar a mais (FICA DIFÍCIL DE REVENDER O CARRO)\n",
    "\n",
    "\n",
    "RMSE: Dá maior peso a erros maiores devido ao quadrado. Também em unidades da variável alvo (£).\tBoa para penalizar erros grandes. Se um erro de £10.000 for muito mais crítico do que dois erros de £5.000, o RMSE será a métrica mais relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['model_mean_price', 'model_popularity', \n",
    "                     'brand_mean_price','premium_brand_engine_size_interaction', \n",
    "                     'engineSize', 'mpg', 'mileage', 'tax'\n",
    "                     'mpg_per_liter', 'age_squared', 'tax_per_engine',\n",
    "                     'transmission_manual', 'fuelType_hybrid', 'fuelType_petrol']\n",
    "\n",
    "\n",
    "selected_features = ['model_mean_price', 'model_popularity', \n",
    "    ela                 'brand_mean_price','premium_brand_engine_size_interaction', \n",
    "                     'engineSize', 'mpg', 'mileage', 'tax',\n",
    "                     'mpg_per_liter', 'age_squared', 'tax_per_engine',\n",
    "                     'transmission_manual', 'fuelType_hybrid', 'fuelType_petrol']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Calculate train and validation metrics\"\"\"\n",
    "    y_train_pred = np.expm1(model.predict(X_train))\n",
    "    y_val_pred = np.expm1(model.predict(X_val))\n",
    "    \n",
    "    scores = {\n",
    "        'Train MAE': mean_absolute_error(y_train, y_train_pred),\n",
    "        'Val MAE': mean_absolute_error(y_val, y_val_pred),\n",
    "        'Train RMSE': root_mean_squared_error(y_train, y_train_pred),\n",
    "        'Val RMSE': root_mean_squared_error(y_val, y_val_pred),\n",
    "        'Train Pinball (α=0.5)': mean_pinball_loss(y_train, y_train_pred, alpha=0.5),\n",
    "        'Val Pinball (α=0.5)': mean_pinball_loss(y_val, y_val_pred, alpha=0.5)\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing model: Linear Regression ---\n",
      "  Params: {} -> Val MAE: 3584.3732\n",
      "Best validation MAE for Linear Regression: 3584.3732\n",
      "\n",
      "--- Processing model: ElasticNet ---\n",
      "  Params: {'alpha': 0.1, 'l1_ratio': 0.1} -> Val MAE: 3574.3183\n",
      "  Params: {'alpha': 0.1, 'l1_ratio': 0.5} -> Val MAE: 3560.8787\n",
      "  Params: {'alpha': 0.1, 'l1_ratio': 0.9} -> Val MAE: 3574.9216\n",
      "  Params: {'alpha': 1.0, 'l1_ratio': 0.1} -> Val MAE: 4612.7643\n",
      "  Params: {'alpha': 1.0, 'l1_ratio': 0.5} -> Val MAE: 4132.4925\n",
      "  Params: {'alpha': 1.0, 'l1_ratio': 0.9} -> Val MAE: 3580.9394\n",
      "  Params: {'alpha': 10.0, 'l1_ratio': 0.1} -> Val MAE: 6287.6545\n",
      "  Params: {'alpha': 10.0, 'l1_ratio': 0.5} -> Val MAE: 5971.1202\n",
      "  Params: {'alpha': 10.0, 'l1_ratio': 0.9} -> Val MAE: 4711.4814\n",
      "Best validation MAE for ElasticNet: 3560.8787\n",
      "\n",
      "--- Processing model: SVR ---\n",
      "  Params: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'} -> Val MAE: 5439.0040\n",
      "  Params: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'} -> Val MAE: 5390.3855\n",
      "  Params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'} -> Val MAE: 3468.7666\n",
      "  Params: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'} -> Val MAE: 3459.1811\n",
      "  Params: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'} -> Val MAE: 2855.0573\n",
      "  Params: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'} -> Val MAE: 2798.1166\n",
      "Best validation MAE for SVR: 2798.1166\n",
      "\n",
      "--- Processing model: Decision Tree ---\n",
      "  Params: {'max_depth': 5, 'min_samples_leaf': 2} -> Val MAE: 3155.0815\n",
      "  Params: {'max_depth': 5, 'min_samples_leaf': 5} -> Val MAE: 3155.0815\n",
      "  Params: {'max_depth': 10, 'min_samples_leaf': 2} -> Val MAE: 2142.9011\n",
      "  Params: {'max_depth': 10, 'min_samples_leaf': 5} -> Val MAE: 2130.2091\n",
      "  Params: {'max_depth': None, 'min_samples_leaf': 2} -> Val MAE: 1744.0329\n",
      "  Params: {'max_depth': None, 'min_samples_leaf': 5} -> Val MAE: 1690.0320\n",
      "Best validation MAE for Decision Tree: 1690.0320\n",
      "\n",
      "--- Processing model: Random Forest ---\n",
      "  Params: {'max_depth': 10, 'min_samples_leaf': 2, 'n_estimators': 100} -> Val MAE: 1967.5746\n",
      "  Params: {'max_depth': 10, 'min_samples_leaf': 4, 'n_estimators': 100} -> Val MAE: 1969.8537\n",
      "  Params: {'max_depth': 10, 'min_samples_leaf': 6, 'n_estimators': 100} -> Val MAE: 1977.8071\n",
      "  Params: {'max_depth': 20, 'min_samples_leaf': 2, 'n_estimators': 100} -> Val MAE: 1425.6523\n",
      "  Params: {'max_depth': 20, 'min_samples_leaf': 4, 'n_estimators': 100} -> Val MAE: 1471.0553\n",
      "  Params: {'max_depth': 20, 'min_samples_leaf': 6, 'n_estimators': 100} -> Val MAE: 1519.0987\n",
      "Best validation MAE for Random Forest: 1425.6523\n",
      "\n",
      "--- Processing model: K-Neighbors ---\n",
      "  Params: {'n_neighbors': 3, 'weights': 'uniform'} -> Val MAE: 1689.4224\n",
      "  Params: {'n_neighbors': 3, 'weights': 'distance'} -> Val MAE: 1660.9744\n",
      "  Params: {'n_neighbors': 5, 'weights': 'uniform'} -> Val MAE: 1685.6135\n",
      "  Params: {'n_neighbors': 5, 'weights': 'distance'} -> Val MAE: 1632.5356\n",
      "  Params: {'n_neighbors': 7, 'weights': 'uniform'} -> Val MAE: 1706.9045\n",
      "  Params: {'n_neighbors': 7, 'weights': 'distance'} -> Val MAE: 1632.2039\n",
      "Best validation MAE for K-Neighbors: 1632.2039\n",
      "\n",
      "--- Processing model: Gradient Boosting ---\n",
      "  Params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 3, 'n_estimators': 200, 'subsample': 1.0} -> Val MAE: 1998.0102\n",
      "  Params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 3, 'n_estimators': 200, 'subsample': 0.8} -> Val MAE: 2001.7923\n",
      "  Params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 5, 'n_estimators': 200, 'subsample': 1.0} -> Val MAE: 1986.0031\n",
      "  Params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 5, 'n_estimators': 200, 'subsample': 0.8} -> Val MAE: 2002.9634\n",
      "  Params: {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 3, 'n_estimators': 200, 'subsample': 1.0} -> Val MAE: 1414.7141\n",
      "  Params: {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 3, 'n_estimators': 200, 'subsample': 0.8} -> Val MAE: 1425.5732\n",
      "  Params: {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 5, 'n_estimators': 200, 'subsample': 1.0} -> Val MAE: 1421.9498\n",
      "  Params: {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 5, 'n_estimators': 200, 'subsample': 0.8} -> Val MAE: 1441.4854\n",
      "Best validation MAE for Gradient Boosting: 1414.7141\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Val MAE</th>\n",
       "      <th>Train MAE</th>\n",
       "      <th>Val RMSE</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Val Pinball (α=0.5)</th>\n",
       "      <th>Train Pinball (α=0.5)</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1414.714125</td>\n",
       "      <td>1228.131137</td>\n",
       "      <td>2332.313310</td>\n",
       "      <td>1840.510040</td>\n",
       "      <td>707.357063</td>\n",
       "      <td>614.065568</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'min_sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1425.652334</td>\n",
       "      <td>830.480952</td>\n",
       "      <td>2535.256951</td>\n",
       "      <td>1516.135196</td>\n",
       "      <td>712.826167</td>\n",
       "      <td>415.240476</td>\n",
       "      <td>{'max_depth': 20, 'min_samples_leaf': 2, 'n_es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Neighbors</td>\n",
       "      <td>1632.203881</td>\n",
       "      <td>19.121401</td>\n",
       "      <td>2860.780896</td>\n",
       "      <td>189.414295</td>\n",
       "      <td>816.101940</td>\n",
       "      <td>9.560701</td>\n",
       "      <td>{'n_neighbors': 7, 'weights': 'distance'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1690.032022</td>\n",
       "      <td>1130.649342</td>\n",
       "      <td>2937.579784</td>\n",
       "      <td>2053.653981</td>\n",
       "      <td>845.016011</td>\n",
       "      <td>565.324671</td>\n",
       "      <td>{'max_depth': None, 'min_samples_leaf': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVR</td>\n",
       "      <td>2798.116590</td>\n",
       "      <td>2758.658422</td>\n",
       "      <td>4800.256846</td>\n",
       "      <td>4723.911399</td>\n",
       "      <td>1399.058295</td>\n",
       "      <td>1379.329211</td>\n",
       "      <td>{'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>3560.878693</td>\n",
       "      <td>3491.782561</td>\n",
       "      <td>5451.197579</td>\n",
       "      <td>5323.794859</td>\n",
       "      <td>1780.439346</td>\n",
       "      <td>1745.891281</td>\n",
       "      <td>{'alpha': 0.1, 'l1_ratio': 0.5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>3584.373188</td>\n",
       "      <td>3509.675604</td>\n",
       "      <td>5426.879092</td>\n",
       "      <td>5287.203839</td>\n",
       "      <td>1792.186594</td>\n",
       "      <td>1754.837802</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model      Val MAE    Train MAE     Val RMSE   Train RMSE  \\\n",
       "6  Gradient Boosting  1414.714125  1228.131137  2332.313310  1840.510040   \n",
       "4      Random Forest  1425.652334   830.480952  2535.256951  1516.135196   \n",
       "5        K-Neighbors  1632.203881    19.121401  2860.780896   189.414295   \n",
       "3      Decision Tree  1690.032022  1130.649342  2937.579784  2053.653981   \n",
       "2                SVR  2798.116590  2758.658422  4800.256846  4723.911399   \n",
       "1         ElasticNet  3560.878693  3491.782561  5451.197579  5323.794859   \n",
       "0  Linear Regression  3584.373188  3509.675604  5426.879092  5287.203839   \n",
       "\n",
       "   Val Pinball (α=0.5)  Train Pinball (α=0.5)  \\\n",
       "6           707.357063             614.065568   \n",
       "4           712.826167             415.240476   \n",
       "5           816.101940               9.560701   \n",
       "3           845.016011             565.324671   \n",
       "2          1399.058295            1379.329211   \n",
       "1          1780.439346            1745.891281   \n",
       "0          1792.186594            1754.837802   \n",
       "\n",
       "                                         Best Params  \n",
       "6  {'learning_rate': 0.1, 'max_depth': 7, 'min_sa...  \n",
       "4  {'max_depth': 20, 'min_samples_leaf': 2, 'n_es...  \n",
       "5          {'n_neighbors': 7, 'weights': 'distance'}  \n",
       "3         {'max_depth': None, 'min_samples_leaf': 5}  \n",
       "2       {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  \n",
       "1                    {'alpha': 0.1, 'l1_ratio': 0.5}  \n",
       "0                                                 {}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EVALUATION FUNCTION \n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    scores = {\n",
    "        'Train MAE': mean_absolute_error(y_train, y_train_pred),\n",
    "        'Val MAE': mean_absolute_error(y_val, y_val_pred),\n",
    "        'Train RMSE': root_mean_squared_error(y_train, y_train_pred),\n",
    "        'Val RMSE': root_mean_squared_error(y_val, y_val_pred),\n",
    "        'Train Pinball (α=0.25)': mean_pinball_loss(y_train, y_train_pred, alpha=0.25),\n",
    "        'Val Pinball (α=0.25)': mean_pinball_loss(y_val, y_val_pred, alpha=0.25)\n",
    "    }\n",
    "    return scores\n",
    "\n",
    "# MODELS AND HYPERPARAMETER GRIDS\n",
    "models_and_grids = {\n",
    "    \"Linear Regression\": {\n",
    "        \"model\": LinearRegression(),\n",
    "        \"params\": {} # Here we have no hyperparameters to tune\n",
    "    },\n",
    "    \"ElasticNet\": {\n",
    "        \"model\": ElasticNet(random_state=37, max_iter=5000),\n",
    "        \"params\": {\n",
    "            'alpha': [0.2, 0.8], # Controls the regularization strength\n",
    "            'l1_ratio': [0.5, 0.9],  # Mix between L1 and L2\n",
    "        }\n",
    "    },\n",
    "    \"SVR\": {\n",
    "        \"model\": SVR(epsilon=0.5),\n",
    "        \"params\": {\n",
    "            'C': [1, 10],      # Regularization parameter\n",
    "            'gamma': ['scale', 'auto'] # Kernel coefficient\n",
    "        }\n",
    "    },\n",
    "    \"KNeighbors\": {\n",
    "        \"model\": KNeighborsRegressor(p=1, n_jobs=-1),\n",
    "        \"params\": {\n",
    "            'n_neighbors': [3, 7],  # Number of neighbors to consider for prediction\n",
    "            'weights': ['distance', 'uniform'], # the way to weight the neighbors \n",
    "        }\n",
    "    },\n",
    "    \"MLP Regressor\": {\n",
    "    \"model\": MLPRegressor(random_state=37, max_iter=500), # max_iter é importante  #it is usually better to have higher number of hidden layers\n",
    "    \"params\": {\n",
    "        'hidden_layer_sizes': [(), (50, 50)], # 1 ou 2 camadas\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam'],\n",
    "        'learning_rate_init': [0.001, 0.01]\n",
    "        }\n",
    "    }, \n",
    "}\n",
    "\n",
    "\n",
    "# __Some rule of thumbs:__\n",
    "# -\tThe number of hidden neurons should be between the size of the input layer and the size of the output layer\n",
    "# -\tThe number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer\n",
    "# -\tThe number of hidden neurons should be less than twice the size of the input layer\n",
    "\n",
    "# \"Decision Tree\": {\n",
    "#         \"model\": DecisionTreeRegressor(random_state=37),\n",
    "#         \"params\": {\n",
    "#             'max_depth': [5, 10, None], # Max depth to control overfitting\n",
    "#             'min_samples_leaf': [2, 5]  # Min samples per leaf\n",
    "#         }\n",
    "#     },\n",
    "#     \"Random Forest\": {\n",
    "#         \"model\": RandomForestRegressor(random_state=37, n_jobs=-1),\n",
    "#         \"params\": {\n",
    "#             'n_estimators': [100],      # Number of trees\n",
    "#             'max_depth': [10, 20],      # Max depth of trees\n",
    "#             'min_samples_leaf': [2, 4, 6] # Min samples per leaf\n",
    "#         }\n",
    "\n",
    "\n",
    "models_and_grids = {\n",
    "    \"Elastic Net\": {\n",
    "        \"model\": ElasticNet(random_state=37, max_iter=10000),\n",
    "        \"params\": {\n",
    "            'alpha': [0.8731, 0.8732, 0.8733, 0.8734, 0.8735, 0.8736, 0.8737, 0.8738, 0.8739], \n",
    "            'l1_ratio': [0.91]\n",
    "        } \n",
    "    },\n",
    "    \"KNeighbors\": {\n",
    "        \"model\": KNeighborsRegressor(n_jobs=-1),\n",
    "        \"params\": {\n",
    "            'n_neighbors': [8],\n",
    "            'weights': ['distance'],\n",
    "            'p': [1]\n",
    "        }\n",
    "    },\n",
    "    \"Extra Tree\": {\n",
    "        \"model\": ExtraTreesRegressor(random_state=37, n_jobs=-1),\n",
    "        \"params\": {\n",
    "            'n_estimators': [240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250],\n",
    "            'max_depth': [22],\n",
    "            'min_samples_leaf': [2],\n",
    "            'max_features': [None]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestRegressor(random_state=37, n_jobs=-1),\n",
    "        \"params\": {\n",
    "            'n_estimators': [450, 460, 470, 480, 490, 500],\n",
    "            'max_depth': [19, 20],\n",
    "            'min_samples_leaf': [1, 2, 3],\n",
    "            'max_features': ['log2', 'sqrt']\n",
    "        }\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingRegressor(random_state=37),\n",
    "        \"params\": {\n",
    "            'learning_rate': [0.01, 0.02],\n",
    "            'max_depth': [11],\n",
    "            'min_samples_leaf': [2],\n",
    "            'n_estimators': [970, 980, 990, 1000],\n",
    "            'subsample': [0.7, 0.75]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    \"Gradient Boosting\": {\n",
    "#         \"model\": GradientBoostingRegressor(random_state=37),        \n",
    "#         \"params\": {\n",
    "#             'learning_rate': [0.1],\n",
    "#             'max_depth': [3,7],\n",
    "#             'min_samples_leaf': [3,5],\n",
    "#             'n_estimators': [200],\n",
    "#             'subsample': [1.0, 0.8]\n",
    "#         }\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training set dimensions (X): (75956, 8)\n",
      "Final training set dimensions (y): (75956,)\n",
      "Creating the submission file...\n",
      "\n",
      "Submission file 'Group37_Version1.csv' exported successfully!\n",
      "First 5 rows of the submission file:\n",
      "    carID         price\n",
      "0   89856  11049.956294\n",
      "1  106581  21575.734207\n",
      "2   80886  12659.515303\n",
      "3  100174  17039.134083\n",
      "4   81376  24774.715679\n"
     ]
    }
   ],
   "source": [
    "#Combining training and validation datasets\n",
    "X_train_full = pd.concat([X_train, X_val])\n",
    "y_train_full = pd.concat([y_train, y_val])\n",
    "\n",
    "print(f\"Final training set dimensions (X): {X_train_full.shape}\")\n",
    "print(f\"Final training set dimensions (y): {y_train_full.shape}\")\n",
    "\n",
    "# Train the Final Model with the Best Hyperparameters\n",
    "best_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 7,\n",
    "    'min_samples_leaf': 3,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 1.0,\n",
    "    'random_state': 37  # Add a random_state for reproducible results\n",
    "}\n",
    "\n",
    "# Instantiate the GradientBoostingRegressor with the best parameters\n",
    "final_model = GradientBoostingRegressor(**best_params)\n",
    "\n",
    "# Train the model on the full combined dataset\n",
    "final_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Make Predictions on the Test Set\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Create and Export the Submission File\n",
    "print(\"Creating the submission file...\")\n",
    "submission_df = pd.DataFrame({\n",
    "    'carID': X_test.index,\n",
    "    'price': test_predictions\n",
    "})\n",
    "\n",
    "# Export to a CSV file without the DataFrame index\n",
    "submission_df.to_csv(\"./project_data/Group37_Version1.csv\", index=False)\n",
    "print(\"\\nSubmission file 'Group37_Version1.csv' exported successfully!\")\n",
    "print(\"First 5 rows of the submission file:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#e5c120ff; padding:15px; border-radius:10px; \n",
    "            box-shadow: 0px 4px 12px rgba(227, 167, 108, 1);\">\n",
    "    <h1 style=\"margin:0; color:white; font-family:sans-serif; font-size:24px;\">\n",
    "         <span style=\"color: #644712ff;\"><b>3 | Regression Benchmarking</b></span>\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"\n",
    "  border: 2px solid #42A5F5;\n",
    "  border-radius: 12px;\n",
    "  background-color: #E3F2FD;\n",
    "  padding: 14px;\n",
    "  font-family: 'Segoe UI', sans-serif;\n",
    "  color: #0D47A1;\n",
    "  box-shadow: 2px 2px 8px rgba(33, 150, 243, 0.15);\n",
    "\">\n",
    "  🚀 <b>O que é preciso:</b><br> \n",
    "\n",
    "**Open-Ended Section**\n",
    " - Objectives for the Section and description of the actions taken <br>\n",
    " - Results and discussion of main findings → key takeaways\n",
    " Note: for example using a feature selection technique not covered in class on your regular pipeline is not sufficient, but explicitly comparing different feature sets would be. <br>\n",
    "\n",
    " Describe your strategy for the additional insights objective. This section is separated into different components:\n",
    "- Formulation and Adequacy of the Objectives: 0.5v\n",
    "-  Difficulty of tasks: 1v\n",
    "- Correctness/efficiency of implementation: 1v\n",
    "- Discussion of results: 1v\n",
    "\n",
    "\n",
    "APAGAR\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUNTAR TUDO NO FINAL E FAZER UM MODELO COM TODOS OS DADOS\n",
    "# Combined train+val for final model training\n",
    "X_train_full_scaled   = pd.concat([X_train_scaled, X_val_scaled], axis=0)\n",
    "y_train_full_array    = np.concatenate([y_train_array, y_val_array])\n",
    "y_train_full_log      = np.concatenate([y_train_log, y_val_log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APAGAR: Parte extra\n",
    "# LINEAR REGRESSION\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_val_pred_lr = lr.predict(X_val)\n",
    "\n",
    "# Save model as pickle file (save as compressed file - sav.gz)\n",
    "import pickle\n",
    "with open('./linear_regression_model.sav.gz', 'wb') as f:\n",
    "    pickle.dump(lr, f)\n",
    "\n",
    "#APAGAR: NO FIM É PRECISO ISTO PARA A APP\n",
    "# Save model\n",
    "with gzip.open('./project_data/linear_regression_model.sav.gz', 'wb') as f:\n",
    "    joblib.dump(lr_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Combined train+val for final model training\n",
    "# X_train_full_scaled   = pd.concat([X_train_scaled, X_val_scaled], axis=0)\n",
    "# y_train_full_array    = np.concatenate([y_train_array, y_val_array])\n",
    "# y_train_full_log      = np.concatenate([y_train_log, y_val_log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. **Setting a Variance Threshold** - useful to deal with features that are constant or quasi-constant - thus, unlikely to be **relevant**\n",
    "# 2. **Correlation Indices** - useful to measure relationships between features - thus, useful to identify **redundant** features - and, under certain conditions also measure relationships between features and the target - thus, useful to help exclude **irrelevant** features.\n",
    "# 3. **Statistical Hypothesis Testing** - useful to measure the relationships between **features and the target** - thus, useful to identify **relevant** features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e5c120ff; padding:15px; border-radius:10px; \n",
    "            box-shadow: 0px 4px 12px rgba(227, 167, 108, 1);\">\n",
    "    <h1 style=\"margin:0; color:white; font-family:sans-serif; font-size:24px;\">\n",
    "         <span style=\"color: #644712ff;\"><b>3 | Regression Benchmarking</b></span>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the **\"No Free Lunch\" theorem**, which suggests that no single algorithm is universally superior for all problems, we implemented a multi-stage benchmarking strategy. We explored five distinct algorithm families covered in classes: **Linear Models (Elastic Net)**, **Distance-based models (K-Nearest Neighbors)**, **Neural Networks (MLP Regressor)**, and **Ensemble methods** including both **Bagging (Random Forest, Extra Trees)** and **Boosting (Gradient Boosting)**.\n",
    "\n",
    "As we have already seen, we adopted a **Holdout validation strategy**, partitioning the data into training and validation sets. This approach ensured a strict separation of data, preventing **Data Leakage** during the preprocessing, feature selection and hyperparameter optimization phases. To finalize the process, we utilized **Stacked Generalization** (Stacking), which incorporates an internal **5-fold Cross-Validation** mechanism to calibrate the meta-estimator, ensuring robust weight allocation without compromising the primary holdout integrity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features =  ['model_mean_price', 'model_popularity', \n",
    "                     'brand_mean_price','premium_brand_engine_size_interaction', \n",
    "                     'engineSize', 'mpg', 'mileage', 'tax',\n",
    "                     'mpg_per_liter', 'age_squared', 'tax_per_engine',\n",
    "                     'transmission_manual', 'fuelType_hybrid', 'fuelType_petrol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate model performance, all predictions were transformed from the logarithmic training scale back to the original currency (£) using the inverse function ($exp(x)-1$). The following metrics were selected:\n",
    "\n",
    "* **Mean Absolute Error (MAE):** Our primary optimization metric. It provides a robust and interpretable measure of the average prediction error in pounds (£). It ensures that extreme values do not disproportionately bias the model's parameters, maintaining focus on the most frequent market transactions.\n",
    "\n",
    "* **Root Mean Squared Error (RMSE):** While we prioritized the median price, we recognized that large errors in high-value cars are financially impactful. RMSE was used as a secondary stability metric. It penalizes larger errors more severely, ensuring the selected model does not produce catastrophic mispricing for specific vehicle segments.\n",
    "\n",
    "* **Pinball Loss (\\alpha=0.3)** [asymmetric Quantile Loss] A business-centric asymmetric metric. By setting \\alpha=0.3, we penalized **overestimation** (predicting a price higher than the actual value) more heavily than underestimation. This aligns with the business goal of ensuring Cars 4 You does not overpay for inventory, thereby protecting profit margins.\n",
    "\n",
    "*Note*: The `evaluate_model` function is included here instead of `util.py` to provide a clear view of the key performance metrics and although the model predictions are made on the log-transformed scale internally, all reported metrics are *converted back to the original price scale (£)*. This ensures that the results are directly interpretable in terms of actual car prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train_original, X_val, y_val_original):\n",
    "    \"\"\"\n",
    "    Evaluate the model and return various metrics on original scale (£)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn estimator\n",
    "        The trained model to evaluate.\n",
    "    X_train : pd.DataFrame\n",
    "        Training features.\n",
    "    y_train_original : np.array\n",
    "        Original training target values (not log-transformed).\n",
    "    X_val : pd.DataFrame\n",
    "        Validation features.\n",
    "    y_val_original : np.array\n",
    "        Original validation target values (not log-transformed).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing MAE, RMSE, and Pinball Loss for both training and validation sets.    \n",
    "    \"\"\"\n",
    "\n",
    "    # Predict on log scale\n",
    "    y_train_pred_log = model.predict(X_train)\n",
    "    y_val_pred_log = model.predict(X_val)\n",
    "    \n",
    "    # Transform predictions back to original scale (£) in order to calculate interpretable metrics\n",
    "    y_train_pred = np.expm1(y_train_pred_log)\n",
    "    y_val_pred = np.expm1(y_val_pred_log)\n",
    "    \n",
    "    scores = {\n",
    "        'Train MAE': mean_absolute_error(y_train_original, y_train_pred),\n",
    "        'Val MAE': mean_absolute_error(y_val_original, y_val_pred),\n",
    "        'Train RMSE': root_mean_squared_error(y_train_original, y_train_pred),\n",
    "        'Val RMSE': root_mean_squared_error(y_val_original, y_val_pred),\n",
    "        'Train Pinball (α=0.3)': mean_pinball_loss(y_train_original, y_train_pred, alpha=0.3),\n",
    "        'Val Pinball (α=0.3)': mean_pinball_loss(y_val_original, y_val_pred, alpha=0.3)\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our optimization strategy was structured in two distinct phases to balance computational efficiency with model robustness, moving from a broad architectural screening to granular hyperparameter refinement.\n",
    "\n",
    "**Phase 1: Hybrid Benchmarking** <BR>\n",
    " We performed an initial screening using **Manual Random Search**, testing up to 4 random hyperparameter combinations for each of the five families.\n",
    "\n",
    " **Gradient Boosting** was the clear frontrunner. It achieved the best results across all validation metrics (**MAE, RMSE, and Pinball Loss**). It demonstrated a somewhat healthy balance between bias and variance; unlike other high-performing models like **K-Nearest Neighbors**, it did not exhibit extreme overfitting, maintaining a realistic generalization ratio.\n",
    "\n",
    "**K-Nearest Neighbors** produced competitive validation scores, but the model exhibited a near-zero training error (Ratio of 0.01), a clear indicator that the model was over-reliant on specific training coordinates rather than learning a generalizable pricing logic, making it unsuitable for a production environment.\n",
    "\n",
    "The Tree-Based Ensemble (**Extra Trees** vs. **Random Forest**) showed strong predictive capabilities, significantly outperforming the linear and neural network baselines. **Extra Trees** achieved slightly superior validation metrics compared to Random Forest. However, it also displayed a higher overfitting ratio (none of them overfit at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOVO: A PARTE P KNN, sgd, min_impurity_decrease\n",
    "# Model configurations and hyperparameter grids (for a manual Random Search)\n",
    "models_and_grids = {\n",
    "    \"Elastic Net\": {\n",
    "        \"model\": ElasticNet(random_state=37, max_iter=2000, tol=0.001),\n",
    "        \"params\": {\n",
    "             'alpha': [0.01, 1, 10], # regularization strength\n",
    "             'l1_ratio': [0.75, 0.5, 0.25] #focus more on l1_ratio or not\n",
    "        } \n",
    "    },\n",
    "    \"KNeighbors\": {\n",
    "        \"model\": KNeighborsRegressor(n_jobs=-1, algorithm='ball_tree'), #ball_tree to speed up\n",
    "        \"params\": {\n",
    "            'n_neighbors': [100, 500], # number of neighbors\n",
    "            'weights': ['distance', 'uniform'], #weight of each neighbor\n",
    "            'p': [1, 2],  #distance metric: 1 for manhattan, 2 for euclidean\n",
    "        }\n",
    "    },\n",
    "    \"MLPRegressor\": {\n",
    "        \"model\": MLPRegressor(random_state=37, max_iter=1500, early_stopping=True,tol= 0.001, n_iter_no_change=15),\n",
    "        \"params\": {\n",
    "            \"hidden_layer_sizes\": [(15,10,7,3), (34, 15, 5)], #following more or less the rule of thumbs we learned in class, this should be ok\n",
    "            #it a common practice to start with layers that funnel down and also multiple layers (depth) are generally better than a single very wide layer\n",
    "            \"activation\": [\"relu\", \"tanh\"], #relu: computationally efficient, helps avoid vanishing gradient problem; tanh: zero-centered, which can help in learning\n",
    "            \"alpha\": [0.01, 0.001], #to prevent overfitting\n",
    "            \"batch_size\": [128, 256], # a little bigger batches to speed up\n",
    "        \n",
    "            \"solver\": [\"adam\", \"sgd\"], # adam: adaptive learning rates, good for most cases; sgd: can be more stable with the right settings (more control)\n",
    "            \"learning_rate_init\": [0.001, 0.01], #initial learning rate shouldn't be too high to avoid overshooting minima or too low to avoid slow convergence \n",
    "\n",
    "            #ADAM specific parameters\n",
    "            \"beta_1\": [0.9], #decay rate for the first moment estimates\n",
    "            \"beta_2\": [0.999], #decay rate for the second moment estimates\n",
    "\n",
    "            #SGD specific parameters\n",
    "            \"learning_rate\": ['adaptive'], #adaptive: keeps the learning rate constant as long as training loss decreases\n",
    "            \"momentum\": [0.9], #helps accelerate gradients vectors in the right directions, thus leading to faster converging\n",
    "            \"nesterovs_momentum\": [True]\n",
    "        }\n",
    "    },\n",
    "    # We know that Decision Trees are usually not strong standalone models (high error, high variance, low stability, and high sensitivity to noise),\n",
    "    # so we will not use them directly. But this is exactly where ensemble learning methods (bagging, boosting,...) come in.\n",
    "\n",
    "    # Bagging ensemble method that uses random splits based on Decision Trees:\n",
    "    \"Extra Tree\": {\n",
    "        \"model\": ExtraTreesRegressor(random_state=37, n_jobs=-1, bootstrap=False), # the split is already random, we don't need bootstrap samples\n",
    "        \"params\": {\n",
    "            'n_estimators': [250, 500], #number of models trained in parallel, we choose high numbers so hopefully it won't overfit and make the result more trustworthy\n",
    "            'max_depth': [15, 20], # not too deep to avoid overfitting\n",
    "            'min_samples_leaf': [15, 30], # to make sure each leaf has enough samples (not too specific)\n",
    "            'max_features': ['sqrt', 0.8] # to introduce randomness and reduce correlation between trees\n",
    "        }\n",
    "    },\n",
    "    #Bagging ensemble method that uses bootstrap samples and bootstrap feature subsets based on Decision Trees\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestRegressor(random_state=37, n_jobs=-1, max_samples=0.7),\n",
    "        \"params\": {\n",
    "            'n_estimators': [300, 500], #number of trees is high to prevent overfitting and improve stability\n",
    "            'max_features': ['sqrt', 1], #use subsets of features to reduce correlation between trees or use all features\n",
    "            'max_depth': [15, 20], #not too deep to avoid overfitting\n",
    "            'min_samples_split': [90,120], #to ensure each split has enough samples\n",
    "            'min_samples_leaf': [15,30], #to ensure each leaf has enough samples\n",
    "        }\n",
    "    },\n",
    "    # Ensemble of sequential trees, each correcting previous errors,combined via weighted sum (learning rate)\n",
    "    \"GradientBoosting\": {\n",
    "        \"model\": GradientBoostingRegressor(random_state=37, loss='absolute_error'),\n",
    "        \"params\": {\n",
    "            'learning_rate': [0.01, 0.05], # low for stability\n",
    "            'max_depth': [5, 8], # low depth for weak learners\n",
    "            'n_estimators': [500, 1000], #to compensate for low learning rate\n",
    "            'subsample': [0.75, 0.85], # subsampling for regularization (anti-overfitting)\n",
    "            'max_features': ['sqrt', 0.8], # to introduce randomness and reduce correlation between trees\n",
    "            'min_samples_leaf': [15, 30] # hopefully sufficient high values to prevent overfitting\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier names\n",
    "y_train_original_for_eval = y_train_array \n",
    "y_val_original_for_eval = y_val_array\n",
    "y_train_log_for_fit = y_train_log\n",
    "\n",
    "########################################################\n",
    "# 1: hybrid benchmarking (MANUAL RANDOM SEARCH)        #\n",
    "########################################################\n",
    "results_list = []\n",
    "\n",
    "print(\"PHASE 1: Initial benchmarking with Manual Random Search\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Loop through each model and its hyperparameter grid\n",
    "for model_name, config in models_and_grids.items():\n",
    "    print(f\"\\n---> Optimizing {model_name}\")\n",
    "    \n",
    "    X_tr = X_train_scaled[selected_features]\n",
    "    X_vl = X_val_scaled[selected_features]\n",
    "    \n",
    "    # Generate all possible parameter combinations\n",
    "    param_combinations = list(product(*config['params'].values()))\n",
    "    param_keys = list(config['params'].keys())\n",
    "\n",
    "    # Select at most 4 random combinations to test\n",
    "    if len(param_combinations) > 4:\n",
    "        tested_params = random.sample(param_combinations, 4)\n",
    "        print(f\"Testing 4 random combinations out of {len(param_combinations)}:\\n\")\n",
    "    else:\n",
    "        tested_params = param_combinations\n",
    "        print(f\"Testing all {len(param_combinations)} combinations:\\n\")\n",
    "\n",
    "    # track the best model and its metrics\n",
    "    best_val_mae = float('inf')\n",
    "    best_result = None\n",
    "\n",
    "    # Loop through the parameters\n",
    "    for values in tested_params:\n",
    "        params = dict(zip(param_keys, values))\n",
    "        model = clone(config['model'])\n",
    "        model.set_params(**params)\n",
    "        model.fit(X_tr, y_train_log_for_fit) # fit on log-price\n",
    "        \n",
    "        scores = evaluate_model(model, X_tr, y_train_original_for_eval, X_vl, y_val_original_for_eval) #gets scores in original scale (£)\n",
    "\n",
    "        # the model with the lowest Val MAE is considered the best model for that family algorithm\n",
    "        if scores['Val MAE'] < best_val_mae:\n",
    "            best_val_mae = scores['Val MAE']\n",
    "            best_result = {\n",
    "                'Model': model_name,\n",
    "                'Best Params': str(params),\n",
    "                **scores,\n",
    "                }\n",
    "            \n",
    "            # Check for overfitting\n",
    "            overfit_ratio = scores['Train MAE'] / scores['Val MAE']\n",
    "            if overfit_ratio < 0.75:\n",
    "                print(f\"    !!! OVERFITTING: Train MAE/Val MAE Ratio < 0.75: {overfit_ratio:.2f} !!!\")\n",
    "            print(f\"  New best: {params} | VAL MAE:{scores['Val MAE']:,.2f} | Pinball(0.3):{scores['Val Pinball (α=0.3)']:.2f} | Val RMSE:{scores['Val RMSE']:.2f} \")\n",
    "\n",
    "    # only adds the best VAL MAE result of each model to the phase 1 results list\n",
    "    if best_result:\n",
    "        results_list.append(best_result)\n",
    "\n",
    "   \n",
    "# Final results phase 1 DataFrame\n",
    "results_df = pd.DataFrame(results_list).sort_values('Val MAE')\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Final benchmarking results per model (phase 1):\")\n",
    "display(results_df[['Model','Train MAE', 'Val MAE','Train Pinball (α=0.3)', 'Val Pinball (α=0.3)','Train RMSE', 'Val RMSE', 'Best Params']])\n",
    "\n",
    "# Get the best parameters from phase 1 for use in phase 2\n",
    "best_params_phase1 = {}\n",
    "for model_name in results_df['Model'].unique():\n",
    "    params_str = results_df[results_df['Model'] == model_name]['Best Params'].values[0]\n",
    "    best_params_phase1[model_name] = eval(params_str)\n",
    "\n",
    "print(\"\\nOptimized Parameters from Phase 1:\")\n",
    "for name, params in best_params_phase1.items():\n",
    "    print(f\" - {name}: {params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented a structured “Quality Funnel” to select our two finalists for Phase 2, prioritizing models that were both accurate and reliable.\n",
    "\n",
    "* **Step 0: Integrity Filter (Severe Overfitting)**\n",
    "  The primary priority was eliminating \"memory-based\" learning. Models with a Generalization Ratio ($\\text{MAE}_{\\text{train}} / \\text{MAE}_{\\text{val}} < 0.50$) were eliminated, removing K-Nearest Neighbors.\n",
    "  \n",
    "* **Step 1: Predictive Performance Screening (MAE)**\n",
    "  Bottom performers on validation MAE (Elastic Net and MLP) were discarded, focusing on high-potential ensemble methods.\n",
    "\n",
    "* **Step 2: Outlier Robustness (RMSE)**\n",
    "  Among Gradient Boosting, Extra Trees, and Random Forest, the model with the highest validation RMSE (Random Forest) was removed. It didn't need to go to the third step where the model with the highest Pinball Loss would be removed.\n",
    "\n",
    "The two finalists selected for Phase 2 are **Gradient Boosting** and **Extra Trees**.<br>\n",
    "While Extra Trees showed a higher initial overfit than Random Forest, we proceeded with it based on its higher predictive ceiling. Our strategy assumes that residual variance will be mitigated during *Phase 2* (Granular Fine-Tuning) and through the Stacked Generalization in *Phase 3*, which acts as a powerful regularizer by weighting models based on their out-of-fold performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selection = results_df.copy()\n",
    "\n",
    "# 0. Severe Overfitting Filter (Ratio >= 0.5)\n",
    "initial_count = len(df_selection)\n",
    "df_selection['Ratio_Phase1'] = df_selection['Train MAE'] / df_selection['Val MAE']\n",
    "df_selection = df_selection[df_selection['Ratio_Phase1'] >= 0.5]\n",
    "\n",
    "if len(df_selection) < initial_count:\n",
    "    discarded = results_df[~results_df.index.isin(df_selection.index)]['Model'].tolist()\n",
    "    print(f\"\\nStep 0: Discarded {initial_count - len(df_selection)} models due to severe Overfitting (Ratio < 0.5): {discarded}\")\n",
    "\n",
    "#      Making we have 2 models to proceed\n",
    "# 1. Discard by MAE: it only discards 2 if there are at least 5 models\n",
    "if len(df_selection) > 4:\n",
    "    df_selection = df_selection.sort_values('Val MAE', ascending=True).head(len(df_selection) - 2)\n",
    "    print(f\"Step 1: Discarded 2 models (worst MAE). Remaining: {df_selection['Model'].tolist()}\")\n",
    "elif len(df_selection) == 4: # If there are exactly 4, just discard 1\n",
    "    df_selection = df_selection.sort_values('Val MAE', ascending=True).head(3)\n",
    "    print(f\"Step 1: Discarded 1 model (worst MAE). Remaining: {df_selection['Model'].tolist()}\")\n",
    "\n",
    "# 2. Discard by RMSE: it only discards 1 if there are more than 2 models\n",
    "if len(df_selection) > 2:\n",
    "    df_selection = df_selection.sort_values('Val RMSE', ascending=True).head(len(df_selection) - 1)\n",
    "    print(f\"Step 2: Discarded 1 model (worst RMSE). Remaining: {df_selection['Model'].tolist()}\")\n",
    "\n",
    "# 3. Final Selection by Pinball: if still more than 2\n",
    "if len(df_selection) > 2:\n",
    "    df_selection = df_selection.sort_values('Val Pinball (α=0.3)', ascending=True).head(2)\n",
    "    print(f\"Step 3: Selected best 2 by Pinball. Remaining: {df_selection['Model'].tolist()}\")\n",
    "else:\n",
    "    # Se já só tiveres 2, apenas garante que estão ordenados\n",
    "    df_selection = df_selection.sort_values('Val Pinball (α=0.3)', ascending=True)\n",
    "\n",
    "# Top 2 models selected\n",
    "top_2_models = df_selection['Model'].tolist()\n",
    "print(f\"The {len(top_2_models)} models selected for phase 2 (Refinement/Stacking) are: {top_2_models}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phase 2: Fine-Tuning and Risk Mitigation**<br>\n",
    "The top two candidates (**Gradient Boosting** and **Extra Trees**) underwent a more granular optimization focusing on generalization and stability. We enforced strict constraints for any model update:\n",
    "\n",
    "1. **Anti-Overfitting Filter:** Any configuration with a Training/Validation MAE ratio below **0.75** was rejected.\n",
    "\n",
    "2. **Stability Check:** New configurations were only accepted if they improved the MAE without degrading the RMSE by more than **5%** or the Pinball Loss by more than **10%** to the current best performing model in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOVO\n",
    "#######################################################################\n",
    "# 2: more refined optimization focusing on top 2 and anti-overfitting #\n",
    "#######################################################################\n",
    "# new grids for the winners of phase 1\n",
    "models_and_grids_phase2 = {}\n",
    "\n",
    "if \"GradientBoosting\" in top_2_models:\n",
    "    models_and_grids_phase2[\"GradientBoosting\"] = {\n",
    "        \"model\": GradientBoostingRegressor(random_state=37, loss='absolute_error'),\n",
    "        \"params\": {\n",
    "            # Explore a bit around the best params found in phase 1\n",
    "            'learning_rate': [0.03, 0.05, 0.07], # explore a bit around 0.05\n",
    "            'max_depth': [7, 8, 9], #explore a bit around depth 8; if 7 is selected, it might reduce overfitting\n",
    "            'n_estimators': [500, 800, 1000], #add 800 to have a middle ground\n",
    "            'subsample': [0.8, 0.85, 0.9], #explore a bit around 0.85\n",
    "            'min_samples_leaf': [25, 30, 35] #explore a bit around 30 (not 15 as before) to prevent overfitting\n",
    "        }\n",
    "    }\n",
    "\n",
    "if \"Extra Tree\" in top_2_models:\n",
    "    models_and_grids_phase2[\"Extra Tree\"] = {\n",
    "        \"model\": ExtraTreesRegressor(random_state=37, n_jobs=-1, bootstrap=False),\n",
    "        \"params\": {\n",
    "            # Explore a bit around the best params found in phase 1\n",
    "            'n_estimators': [500, 600, 700], #choosing higher values that before to deminish variance\n",
    "            'max_depth': [18, 20, 22, 25], #explore a bit around 20; higher depth might bring a little overfitting...but we will control it with min_samples_leaf and evenually with stacking\n",
    "            'min_samples_leaf': [10, 15, 20], #explore a bit around 15\n",
    "            'max_features': [0.7, 0.8, 0.9] #explore a bit around 0.8. 0.7 introduces randomness and reduce correlation between trees while 0.9 allows each tree to have more information but risk overfitting (but we are currently good on overfitting)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Optimization Loop for Phase 2\n",
    "results_list_phase2 = []\n",
    "print(\"\\nPHASE 2: More Fine-Tuning & Exploration (Top Models: GB & Extra Trees)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name, config in models_and_grids_phase2.items():\n",
    "    print(f\"\\n---> Refinement: {model_name}\")\n",
    "    \n",
    "    X_tr = X_train_scaled[selected_features]\n",
    "    X_vl = X_val_scaled[selected_features]\n",
    "\n",
    "    # Initialize with the Phase 1 best model\n",
    "    best_params_f1 = best_params_phase1[model_name]\n",
    "    model_f1 = clone(config['model']).set_params(**best_params_f1)\n",
    "    model_f1.fit(X_tr, y_train_log_for_fit)\n",
    "    \n",
    "    # Scores for comparison\n",
    "    best_scores_p2 = evaluate_model(model_f1, X_tr, y_train_original_for_eval, X_vl, y_val_original_for_eval)\n",
    "    best_val_mae_p2 = best_scores_p2['Val MAE']\n",
    "    curr_best_rmse = best_scores_p2['Val RMSE']\n",
    "    curr_best_pinball = best_scores_p2['Val Pinball (α=0.3)']\n",
    "    \n",
    "    best_result_phase2 = {\n",
    "        'Model': model_name,\n",
    "        'Best Params': str(best_params_f1),\n",
    "        'MAE_Ratio': best_scores_p2['Train MAE'] / best_scores_p2['Val MAE'],\n",
    "        'Source': 'Phase 1 Winner',\n",
    "        **best_scores_p2,\n",
    "    }\n",
    "    \n",
    "    print(f\"  Base (Phase 1): {best_params_f1} | MAE: {best_val_mae_p2:,.2f}\")\n",
    "\n",
    "    # Try 10 new random parameter combinations\n",
    "    param_combinations = list(product(*config['params'].values()))\n",
    "    param_keys = list(config['params'].keys())\n",
    "    tested_params = random.sample(param_combinations, min(len(param_combinations), 10))\n",
    "    \n",
    "    for values in tested_params:\n",
    "        params = dict(zip(param_keys, values))\n",
    "        if params == best_params_f1: continue\n",
    "            \n",
    "        model = clone(config['model']).set_params(**params)\n",
    "        model.fit(X_tr, y_train_log_for_fit)\n",
    "        scores = evaluate_model(model, X_tr, y_train_original_for_eval, X_vl, y_val_original_for_eval)\n",
    "        \n",
    "        ovf_ratio = scores['Train MAE'] / scores['Val MAE']\n",
    "        \n",
    "        # I. Anti-Overfitting Filter (Ratio > 0.75)\n",
    "        if ovf_ratio < 0.75:\n",
    "            print(f\"   [REJECTED - OVF] Ratio: {ovf_ratio:.2f} | Params: {params}\")\n",
    "            continue\n",
    "            \n",
    "        # II. Stability check (RMSE < 5% degradation, Pinball < 10%)\n",
    "        rmse_limit = curr_best_rmse * 1.05\n",
    "        pinball_limit = curr_best_pinball * 1.10\n",
    "        \n",
    "        if scores['Val RMSE'] > rmse_limit or scores['Val Pinball (α=0.3)'] > pinball_limit:\n",
    "            print(f\"   [REJECTED - STABILITY] MAE might be better, but RMSE/Pinball degraded too much. Params: {params}\")\n",
    "            continue\n",
    "\n",
    "        # III. Update if MAE is better\n",
    "        if scores['Val MAE'] < best_val_mae_p2:\n",
    "            best_val_mae_p2 = scores['Val MAE']\n",
    "            curr_best_rmse = scores['Val RMSE']\n",
    "            curr_best_pinball = scores['Val Pinball (α=0.3)']\n",
    "            \n",
    "            best_result_phase2 = {\n",
    "                'Model': model_name,\n",
    "                'Best Params': str(params),\n",
    "                'MAE_Ratio': ovf_ratio,\n",
    "                'Source': 'Phase 2 Improvement',\n",
    "                **scores,\n",
    "            }\n",
    "            print(f\" New Improvement Found for {model_name}:\")\n",
    "            print(f\" Train MAE: {scores['Train MAE']:,.2f} | Val MAE: {scores['Val MAE']:,.2f}\")\n",
    "            print(f\" Train Pinball: {scores['Train Pinball (α=0.3)']:,.2f} | Val Pinball: {scores['Val Pinball (α=0.3)']:,.2f}\")\n",
    "            print(f\" Train RMSE: {scores['Train RMSE']:,.2f} | Val RMSE: {scores['Val RMSE']:,.2f}\")\n",
    "            print(f\" Overfitting Ratio: {ovf_ratio:.2f}\\n\")\n",
    "\n",
    "    results_list_phase2.append(best_result_phase2)\n",
    "\n",
    "# Final Results Visualization\n",
    "results_df_phase2 = pd.DataFrame(results_list_phase2).sort_values('Val MAE')\n",
    "display(results_df_phase2[['Model','Train MAE', 'Val MAE','MAE_Ratio','Train Pinball (α=0.3)', 'Val Pinball (α=0.3)','Train RMSE', 'Val RMSE', 'Best Params']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **Gradient Boosting**, we achieved a refined validation MAE of **1,270.62** (compared to the previous 1,309.13) with just a little more overfit but nothing special (current overfit ratio: 1,078.53/1,270.62=85%; before:1170.87/1309.13=89%). Several configurations didn't achieve better validation MAE or even if they did, they were rejected because they significantly increased the RMSE (stability) or Pinball Loss (business risk).\n",
    "\n",
    "For **Extra Trees**, we improved the validation MAE from 1508.46 to **1,430.52** with a little worse overfitting ratio (current: 1,310.77/1,430.51=92%; before:1,431.96/1,508.46=95%). With this model there were actually more actual improvements with less rejections than with Gradient Boosting.\n",
    "\n",
    "What if if try to combine both models, could we possibly get better results? This is what we did in the next section.\n",
    "\n",
    "---\n",
    "\n",
    "To capitalize on the diverse learning mechanisms of our finalists, we built a **Stacking Regressor**. This ensemble used the optimized **Gradient Boosting** (Boosting) and **Extra Trees** (Bagging) as base estimators. A **Ridge Regressor** (\\alpha=10.0) was employed as the meta-estimator (final judge). The meta-estimator was trained using **out-of-fold predictions** via internal 5-fold cross-validation to ensure the weights were assigned based on true generalization capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# 3: Stacking Benchmark                       #\n",
    "###############################################\n",
    "# Prepare the base estimators with Phase 2 parameters only\n",
    "final_estimators = []\n",
    "for result in results_list_phase2:\n",
    "    name = result['Model']\n",
    "    params = eval(result['Best Params']) \n",
    "    model_instance = clone(models_and_grids[name]['model']) # Create the model instance from the original dictionary\n",
    "    \n",
    "    # Apply only the Phase 2 parameters (which are already optimized)\n",
    "    model_instance.set_params(**params)\n",
    "    \n",
    "    #clean name for the estimator\n",
    "    final_estimators.append((name.lower().replace(\" \", \"_\"), model_instance))\n",
    "\n",
    "# Create the Stacking Regressor: Ridge(alpha=10.0) acts as the meta-learner (judge)\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=final_estimators,\n",
    "    final_estimator=Ridge(alpha=10.0), \n",
    "    cv=5, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the Stacking Ensemble using the best models from Phase 2\n",
    "print(f\"Benchmarking Stacking Ensemble with: {[e[0] for e in final_estimators]}...\")\n",
    "stacking_model.fit(X_tr, y_train_log_for_fit)\n",
    "\n",
    "# evaluate the Stacking Ensemble\n",
    "stacking_scores = evaluate_model(stacking_model,X_tr, y_train_original_for_eval, X_vl, y_val_original_for_eval)\n",
    "\n",
    "# Dictionary to hold stacking results\n",
    "stacking_result = {\n",
    "    'Model': 'Stacking Ensemble (Final)',\n",
    "    'Train MAE': stacking_scores['Train MAE'],\n",
    "    'Val MAE': stacking_scores['Val MAE'],\n",
    "    'MAE_Ratio': stacking_scores['Train MAE'] / stacking_scores['Val MAE'],\n",
    "    'Train Pinball (α=0.3)': stacking_scores['Train Pinball (α=0.3)'],\n",
    "    'Val Pinball (α=0.3)': stacking_scores['Val Pinball (α=0.3)'],\n",
    "    'Train RMSE': stacking_scores['Train RMSE'],\n",
    "    'Val RMSE': stacking_scores['Val RMSE'],\n",
    "    'Best Params': 'Meta: Ridge(alpha=10.0)'\n",
    "}\n",
    "\n",
    "# Join Phase 2 results with Stacking results for final comparison\n",
    "comparison_df = pd.concat([\n",
    "    results_df_phase2, \n",
    "    pd.DataFrame([stacking_result])\n",
    "], ignore_index=True).sort_values('Val MAE')\n",
    "\n",
    "print(\"Final Performance Comparison: Individual Models (Phase 2) vs. Stacking\")\n",
    "display(comparison_df[['Model','Train MAE', 'Val MAE','MAE_Ratio',\n",
    "                       'Train Pinball (α=0.3)', 'Val Pinball (α=0.3)',\n",
    "                       'Train RMSE', 'Val RMSE', 'Best Params']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on full dataset\n",
    "print(f\"\\nTraining Final Stacking Ensemble with: {[e[0] for e in final_estimators]}\")\n",
    "stacking_model.fit(X_train_full_scaled[selected_features], y_train_full_log)\n",
    "\n",
    "# Ensure we use exactly the same columns for test data as in training\n",
    "X_test_final = X_test_scaled[selected_features]\n",
    "\n",
    "# Make predictions (price is still in log scale)\n",
    "test_preds_log = stacking_model.predict(X_test_final)\n",
    "\n",
    "# Inverse transformation from log scale to original price scale\n",
    "test_predictions_final = np.expm1(test_preds_log)\n",
    "\n",
    "# Export submission file\n",
    "print(\"Creating the submission file...\")\n",
    "submission_df = pd.DataFrame({\n",
    "    'carID': X_test_final.index,\n",
    "    'price': test_predictions_final\n",
    "})\n",
    "\n",
    "# Export to CSV\n",
    "filename = \"./project_data/Group37_Version31.csv\"\n",
    "submission_df.to_csv(filename, index=False)\n",
    "\n",
    "print(\"\\nFirst 5 rows of the final file:\")\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####**Final Results Summary**| Model | Train MAE | Val MAE | MAE Ratio | Val RMSE | Val Pinball (0.3) |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| **Gradient Boosting (Best Single)** | 1,078.53 | 1,270.62 | 0.85 | 2,231.86 | 602.68 |\n",
    "| **Extra Trees (Best Single)** | 1,310.77 | 1,430.52 | 0.92 | 2,542.73 | 670.74 |\n",
    "| **Final Stacking Ensemble** | **1,094.94** | **1,094.77** | **1.00** | --- | --- |\n",
    "\n",
    "**Conclusion:** The **Stacking Ensemble** outperformed all individual models, achieving a Final Validation MAE of **£1,094.77**. Most notably, the model achieved a perfect Train/Val Ratio (1.00), indicating exceptional stability and elimination of overfitting. By combining the bias-reduction of Boosting with the variance-reduction of Bagging, the Stacking approach provided the most reliable pricing engine for the business.\n",
    "\n",
    "####**Final Deployment**For the Kaggle submission, the Stacking Ensemble was re-trained on the **full dataset** (combined Training and Validation sets) to maximize the information available for learning, ensuring the highest possible accuracy for the independent test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurate LIME explainer: we use the full training data\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_train_full_scaled[selected_features].values,\n",
    "    feature_names=selected_features,\n",
    "    mode='regression',\n",
    "    verbose=True,\n",
    "    random_state=37\n",
    ")\n",
    "\n",
    "#Choose a specific row from the test set to explain\n",
    "row_idx = 0 \n",
    "observation = X_test_scaled[selected_features].iloc[row_idx]\n",
    "\n",
    "def predict_fn_with_names(x_array):\n",
    "    #converts the numpy array back to DataFrame with original names\n",
    "    x_df = pd.DataFrame(x_array, columns=selected_features)\n",
    "    #predict original price from log predictions\n",
    "    return np.expm1(stacking_model.predict(x_df))\n",
    "\n",
    "print(f\"Generating explanation for the car (carID): {X_test_scaled.index[row_idx]}...\")\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=observation.values, \n",
    "    predict_fn=predict_fn_with_names,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "display(HTML(exp.as_html()))\n",
    "\n",
    "price_predicted = predict_fn_with_names(observation.values.reshape(1, -1))[0]\n",
    "print(f\"\\nPredicted Price by Stacking: £{price_predicted:,.2f}\")\n",
    "\n",
    "print(\"\\nTop 5 Features Influencing this prediction:\")\n",
    "for feature, weight in exp.as_list()[:5]:\n",
    "    direction = \"Increases price\" if weight > 0 else \"Decreases price\"\n",
    "    print(f\" -> {feature:30} | Weight: {weight:8.2f} | {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Utilizámos o LIME para uma explicação local, o que significa que não estamos a ver o que é importante para todos os carros, mas sim o que foi determinante para este carro específico. Isto é vital para a transparência do modelo, permitindo entender se o Stacking está a tomar decisões baseadas em lógica económica (ex: penalizar carros mais velhos) ou em ruído.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
