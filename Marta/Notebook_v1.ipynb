{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7a7ed2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thefuzz in c:\\users\\utilizador\\anaconda3\\envs\\fall2526\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in c:\\users\\utilizador\\anaconda3\\envs\\fall2526\\lib\\site-packages (from thefuzz) (3.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b7b21be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "67417065",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Utilizador\\OneDrive\\Documentos\\NovaIms\\MachineLearning\\Project_data\\test.csv\")\n",
    "train = pd.read_csv(r\"C:\\Users\\Utilizador\\OneDrive\\Documentos\\NovaIms\\MachineLearning\\Project_data\\train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ff703",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb94a0",
   "metadata": {},
   "source": [
    "### carID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "44a5c0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "      <th>paintQuality%</th>\n",
       "      <th>previousOwners</th>\n",
       "      <th>hasDamage</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [carID, Brand, model, year, transmission, mileage, fuelType, tax, mpg, engineSize, paintQuality%, previousOwners, hasDamage, price]\n",
       "Index: []"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat = pd.concat([df, train], ignore_index=True)\n",
    "\n",
    "duplicates = df_concat.duplicated().any()\n",
    "print(duplicates)\n",
    "\n",
    "df_concat[df_concat.duplicated(['carID'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52c4e5",
   "metadata": {},
   "source": [
    "<b>An attribute that contains an identifier for each car.\n",
    "* The carID variable is 100% distinct across all records, hence we can use it as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d6f0cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([\"carID\"])\n",
    "train = train.set_index([\"carID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee2a27",
   "metadata": {},
   "source": [
    "### Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e52c3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VW' 'Toyota' 'Audi' 'Ford' 'BMW' 'Skoda' 'Opel' 'Mercedes' 'FOR'\n",
      " 'mercedes' 'Hyundai' 'w' 'ord' 'MW' 'bmw' nan 'yundai' 'BM' 'Toyot' 'udi'\n",
      " 'Ope' 'AUDI' 'V' 'opel' 'pel' 'For' 'pe' 'Mercede' 'audi' 'MERCEDES'\n",
      " 'OPEL' 'koda' 'FORD' 'Hyunda' 'W' 'Aud' 'vw' 'hyundai' 'skoda' 'ford'\n",
      " 'TOYOTA' 'ercedes' 'oyota' 'toyota' 'SKODA' 'Skod' 'HYUNDAI' 'kod' 'v'\n",
      " 'for' 'SKOD' 'aud' 'KODA' 'PEL' 'yunda' 'or' 'UDI' 'OYOTA' 'HYUNDA' 'mw'\n",
      " 'OPE' 'mercede' 'ERCEDES' 'ercede' 'TOYOT' 'MERCEDE' 'ORD' 'ud' 'ope'\n",
      " 'AUD' 'hyunda' 'skod' 'toyot']\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Brand\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isto é o csv que é criado com recurso a api. Não vale a pena por a correr porque demora muito. Mas o ficheiro vai com o nome cars_api_request\n",
    "#depois tem tudo de ser revisto porque esta bue gpt e com lixo\n",
    "brand_model_dic = pd.read_csv(r\"C:\\Users\\Utilizador\\OneDrive\\Documentos\\NovaIms\\MachineLearning\\brands_models.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c345b71f",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "87e3724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      " Focus        2721\n",
      " C Class      2037\n",
      " Fiesta       1813\n",
      " Golf         1317\n",
      " Corsa         942\n",
      "              ... \n",
      "YARIS            1\n",
      " I3              1\n",
      "yaris            1\n",
      "Combo Life       1\n",
      " GOLF SV         1\n",
      "Name: count, Length: 593, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3449ecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "7                  19\n",
      "3                  11\n",
      "5                  11\n",
      "S5                  8\n",
      "S7                  8\n",
      "                   ..\n",
      "Grand Lion 1949     1\n",
      "Grand Lion 1986     1\n",
      "Landmark            1\n",
      "Little Tiger        1\n",
      "Terralord           1\n",
      "Name: count, Length: 5106, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(brand_model_dic[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c9478",
   "metadata": {},
   "source": [
    "Fazer fuzzmatching com os modelos sabendo que em caso de duvida podemos olhar para a marca. Mas so preenchemos/alteramos quando temos 0.95 ou mais de certeza\n",
    "Se o modelo for unico, ignorar o valor de brand e meter a correta.\n",
    "Se nao for unico, vamos fazer fuzzmathcing com brand a ver qual é que se adapta melhor dentro do universo de marcas que têm esse modelo.\n",
    "Se houver model vazio, mas houve brand. Fazer fuzzy mathcing para a brand, escolher brand e depois dentro dessa brand escolher o modelo mais comun.\n",
    "Se não houve brand nem model. Escolher a combinação modelo/brand mais comum e prencher com isso\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a674e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aqui faço uma normalização basica primeiro par isto nao se passar so porque tem maiusculas e espaços e quês\n",
    "train[\"Brand\"] = train[\"Brand\"].str.lower().str.strip()\n",
    "train[\"model\"] = train[\"model\"].str.lower().str.strip()\n",
    "brand_model_dic[\"brand\"] = brand_model_dic[\"brand\"].str.lower().str.strip()\n",
    "brand_model_dic[\"model\"] = brand_model_dic[\"model\"].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "02217f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de sinónimos relevantes (sem duplicar maiúsculas/minúsculas)\n",
    "brand_aliases = {\n",
    "    \"vw\": \"volkswagen\",\n",
    "    \"mb\": \"mercedes-benz\",\n",
    "    \"mercedes benz\": \"mercedes-benz\",\n",
    "    \"alfa\": \"alfa romeo\",\n",
    "    \"alfa-romeo\": \"alfa romeo\",\n",
    "    \"lr\": \"land rover\",\n",
    "    \"range rover\": \"land rover\",\n",
    "    \"vauxhall\": \"opel\",\n",
    "    \"ds\": \"ds automobiles\",\n",
    "}\n",
    "\n",
    "# Adiciona as equivalências ao teu brand_model_dic (já normalizado)\n",
    "alias_rows = [{\"brand\": canonical, \"model\": \"\"} for canonical in set(brand_aliases.values())]\n",
    "alias_rows += [{\"brand\": alias, \"model\": \"\"} for alias in brand_aliases.keys()]\n",
    "brand_alias_df = pd.DataFrame(alias_rows)\n",
    "\n",
    "brand_model_dic = pd.concat([brand_model_dic, brand_alias_df], ignore_index=True)\n",
    "brand_model_dic.drop_duplicates(subset=[\"brand\", \"model\"], inplace=True)\n",
    "brand_model_dic.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "babb82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Brand\"] = (\n",
    "    train[\"Brand\"]\n",
    "      .astype(str)\n",
    "      .str.strip()\n",
    "      .str.lower()           # já normalizas, mas fica aqui para ser à prova de bala\n",
    "      .replace(brand_aliases)  # mapeia alias -> canónico (vw->volkswagen, mb->mercedes-benz, etc.)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5c3434de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['volkswagen' 'toyota' 'audi' 'ford' 'bmw' 'skoda' 'opel' 'mercedes' 'for'\n",
      " 'hyundai' 'w' 'ord' 'mw' 'nan' 'yundai' 'bm' 'toyot' 'udi' 'ope' 'v'\n",
      " 'pel' 'pe' 'mercede' 'koda' 'hyunda' 'aud' 'ercedes' 'oyota' 'skod' 'kod'\n",
      " 'yunda' 'or' 'ercede' 'ud']\n"
     ]
    }
   ],
   "source": [
    "print(train[\"Brand\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7434a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tenho de rever esta função toda porque primeiro tá bue gpt. Depois esta a dar erros, mas ja da para ter uma ideia.\n",
    "#em vez de substituir as colunas estou a criar novas para conseguir comparar as alterações\n",
    "import re\n",
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# ---------------- utils ----------------\n",
    "try:\n",
    "    def fuzzy_best(query, choices):\n",
    "        \"\"\"Fuzzy sobre a lista ORIGINAL 'choices'. Devolve (string_escolhida, score[0..1], idx).\"\"\"\n",
    "        if not choices:\n",
    "            return None, 0.0, None\n",
    "        q = str(query).strip().lower()\n",
    "        choices_norm = [str(c).strip().lower() for c in choices]\n",
    "        c_wr = process.extractOne(q, choices_norm, scorer=fuzz.WRatio)\n",
    "        c_ts = process.extractOne(q, choices_norm, scorer=fuzz.token_set_ratio)\n",
    "        opts = [c for c in (c_wr, c_ts) if c]\n",
    "        if not opts:\n",
    "            return None, 0.0, None\n",
    "        best = max(opts, key=lambda c: c[1])\n",
    "        idx = best[2]; score = best[1] / 100.0\n",
    "        return choices[idx], score, idx\n",
    "except Exception:\n",
    "    from difflib import SequenceMatcher\n",
    "    def _sim(a,b): return SequenceMatcher(None, a, b).ratio()\n",
    "    def fuzzy_best(query, choices):\n",
    "        if not choices:\n",
    "            return None, 0.0, None\n",
    "        q = str(query).strip().lower()\n",
    "        best_item, best_sc, best_idx = None, 0.0, None\n",
    "        for i,c in enumerate(choices):\n",
    "            sc = _sim(q, str(c).strip().lower())\n",
    "            if sc > best_sc: best_item, best_sc, best_idx = c, sc, i\n",
    "        return best_item, best_sc, best_idx\n",
    "\n",
    "NULL_TOKENS = {\"\", \"nan\", \"none\", \"null\", \"n/a\", \"na\", \"-\"}\n",
    "\n",
    "def norm_text(s: str) -> str:\n",
    "    return str(s).strip().lower()\n",
    "\n",
    "def nullify(x) -> str:\n",
    "    s = \"\" if x is None else str(x).strip()\n",
    "    return \"\" if s.lower() in NULL_TOKENS else s\n",
    "\n",
    "def norm_key(s: str) -> str:\n",
    "    \"\"\"Chave alfanumérica (remove espaços/pontuação): 'a-class'≡'aclass', 'up!'≡'up'.\"\"\"\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", norm_text(s))\n",
    "\n",
    "# ----------- aliases de brand (corrigem typos/abreviações) -----------\n",
    "BRAND_ALIASES = {\n",
    "    \"vauxhall\": \"opel\",\n",
    "    \"for\": \"ford\", \"ord\": \"ford\",\n",
    "    \"mw\": \"bmw\", \"bm\": \"bmw\",\n",
    "    \"mercede\": \"mercedes-benz\", \"ercedes\": \"mercedes-benz\", \"mercedes\": \"mercedes-benz\",\n",
    "    \"aud\": \"audi\", \"udi\": \"audi\",\n",
    "    \"yundai\": \"hyundai\",\n",
    "    \"skod\": \"skoda\",\n",
    "    \"toyot\": \"toyota\",\n",
    "    \"ope\": \"opel\", \"pel\": \"opel\",\n",
    "    # ativa se fizer sentido:\n",
    "    # \"w\": \"volkswagen\", \"v\": \"volkswagen\",\n",
    "}\n",
    "\n",
    "# ----------- normalizações específicas por brand (model) -----------\n",
    "def brand_model_normalize(brand_can: str, model_raw: str) -> str:\n",
    "    m = norm_text(model_raw)\n",
    "    b = norm_text(brand_can)\n",
    "\n",
    "    # Mercedes \"classes\": usar hífen; SUVs GL* idem\n",
    "    m = re.sub(r\"^([abcegs])\\s*class$\", r\"\\1-class\", m)\n",
    "    m = re.sub(r\"^(gla|glb|glc|gle|gls)\\s*class$\", lambda mo: f\"{mo.group(1)}-class\", m)\n",
    "\n",
    "    # VW up → 'up!' (a chave ignora '!')\n",
    "    if b in {\"volkswagen\", \"vw\"}:\n",
    "        if m in {\"u\", \"up\", \"up !\", \"up!\", \"up!!\"}:\n",
    "            m = \"up!\"\n",
    "\n",
    "    # Opel: Viva = Karl; zafira toure -> tourer\n",
    "    if b == \"opel\":\n",
    "        if m == \"viva\": m = \"karl\"\n",
    "        m = m.replace(\"zafira toure\", \"zafira tourer\")\n",
    "\n",
    "    return m\n",
    "\n",
    "# ---------------- pipeline principal ----------------\n",
    "def clean(\n",
    "    train: pd.DataFrame,\n",
    "    brands_models: pd.DataFrame,\n",
    "    thr_brand: float = 0.93,          # fuzzy para brand\n",
    "    thr_model_in_brand: float = 0.93,  # fuzzy do model DENTRO da brand (primeiro)\n",
    "    thr_model_unique: float = 0.97     # fuzzy global p/ assumir model único quando brand vazia\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    # MASTER\n",
    "    bm = brands_models.copy()\n",
    "    bm[\"brand\"] = bm[\"brand\"].map(nullify)\n",
    "    bm[\"model\"] = bm[\"model\"].map(nullify)\n",
    "    bm = bm[(bm[\"brand\"]!=\"\") & (bm[\"model\"]!=\"\")]\n",
    "\n",
    "    brands = sorted(bm[\"brand\"].unique().tolist())\n",
    "    models  = sorted(bm[\"model\"].unique().tolist())\n",
    "\n",
    "    brand_to_models = (\n",
    "        bm.groupby(\"brand\")[\"model\"].apply(lambda s: list(dict.fromkeys(s.tolist()))).to_dict()\n",
    "    )\n",
    "    # mapas para igualdade forte por chave\n",
    "    brand_to_models_keymap = {b: {norm_key(m): m for m in mods} for b,mods in brand_to_models.items()}\n",
    "    model_to_brands = (\n",
    "        bm.groupby(\"model\")[\"brand\"].apply(lambda s: list(dict.fromkeys(s.tolist()))).to_dict()\n",
    "    )\n",
    "\n",
    "    # DATASET base\n",
    "    df = train.copy()\n",
    "    if \"Brand\" not in df.columns or \"model\" not in df.columns:\n",
    "        raise KeyError(\"Esperava colunas 'Brand' e 'model' no train.\")\n",
    "    df[\"brand_new\"] = df[\"Brand\"].map(nullify)\n",
    "    df[\"model_new\"] = df[\"model\"].map(nullify)\n",
    "\n",
    "    # 1) BRAND: aliases → fuzzy (se não bater limiar, fica vazio)\n",
    "    df[\"brand_new\"] = df[\"brand_new\"].map(lambda x: BRAND_ALIASES.get(norm_text(x), x) if x!=\"\" else \"\")\n",
    "    fixed_brands = []\n",
    "    for b in df[\"brand_new\"]:\n",
    "        if b == \"\":\n",
    "            fixed_brands.append(\"\")\n",
    "        elif b in brands:\n",
    "            fixed_brands.append(b)\n",
    "        else:\n",
    "            cand, sc, _ = fuzzy_best(b, brands)\n",
    "            fixed_brands.append(cand if (cand and sc >= thr_brand) else \"\")\n",
    "    df[\"brand_new\"] = fixed_brands\n",
    "\n",
    "    # 2) MODEL COM BRAND FIXA: tentar SEMPRE fuzzy DENTRO da brand; só se falhar é que fica vazio\n",
    "    new_models = []\n",
    "    for b, m in zip(df[\"brand_new\"], df[\"model_new\"]):\n",
    "        if b == \"\":\n",
    "            new_models.append(m)  # tratará no passo seguinte\n",
    "            continue\n",
    "        # normalização específica e igualdade por chave\n",
    "        m_normed = brand_model_normalize(b, m)\n",
    "        key = norm_key(m_normed)\n",
    "        allowed_map = brand_to_models_keymap.get(b, {})\n",
    "        if key and key in allowed_map:\n",
    "            new_models.append(allowed_map[key]); continue\n",
    "        # fuzzy RESTRITO aos modelos dessa brand\n",
    "        candidates = brand_to_models.get(b, [])\n",
    "        cand, sc, _ = fuzzy_best(m_normed, candidates)\n",
    "        if cand is not None and sc >= thr_model_in_brand:\n",
    "            new_models.append(cand)\n",
    "        else:\n",
    "            new_models.append(\"\")  # falhou fuzzy -> deixa vazio (vamos preencher mais tarde pelo mais comum)\n",
    "    df[\"model_new\"] = new_models\n",
    "\n",
    "    # 3) BRAND vazia mas MODEL “certo e ÚNICO” → preencher brand\n",
    "    filled_brands = []\n",
    "    for b, m in zip(df[\"brand_new\"], df[\"model_new\"]):\n",
    "        if b != \"\":\n",
    "            filled_brands.append(b); continue\n",
    "        if m == \"\":\n",
    "            filled_brands.append(\"\"); continue\n",
    "        # tentar casar ao master por chave; senão fuzzy global forte\n",
    "        m_can = None\n",
    "        mk = norm_key(m)\n",
    "        for mm in models:\n",
    "            if norm_key(mm) == mk:\n",
    "                m_can = mm; break\n",
    "        if m_can is None:\n",
    "            cand, sc, _ = fuzzy_best(m, models)\n",
    "            if cand and sc >= thr_model_unique:\n",
    "                m_can = cand\n",
    "        if m_can:\n",
    "            brands_for_m = model_to_brands.get(m_can, [])\n",
    "            filled_brands.append(brands_for_m[0] if len(brands_for_m)==1 else \"\")\n",
    "        else:\n",
    "            filled_brands.append(\"\")\n",
    "    df[\"brand_new\"] = filled_brands\n",
    "\n",
    "    # 4) MODEL vazio/errado mas BRAND certa → usar modelo MAIS COMUM dessa brand no TEU dataset\n",
    "    valid_pairs = df[(df[\"brand_new\"]!=\"\") & (df[\"model_new\"]!=\"\")]\n",
    "    brand_top_model_ds = {}\n",
    "    if len(valid_pairs):\n",
    "        vc = valid_pairs.value_counts([\"brand_new\",\"model_new\"]).reset_index(name=\"n\")\n",
    "        for b in vc[\"brand_new\"].unique():\n",
    "            sub = vc[vc[\"brand_new\"]==b].sort_values(\"n\", ascending=False)\n",
    "            brand_top_model_ds[b] = sub.iloc[0][\"model_new\"]\n",
    "    need_fill = (df[\"brand_new\"]!=\"\") & (df[\"model_new\"]==\"\")\n",
    "    df.loc[need_fill, \"model_new\"] = df.loc[need_fill, \"brand_new\"].map(brand_top_model_ds).fillna(\"\")\n",
    "\n",
    "    # 5) Ambos vazios → par (brand, model) mais comum (dataset → master)\n",
    "    valid_pairs = df[(df[\"brand_new\"]!=\"\") & (df[\"model_new\"]!=\"\")]\n",
    "    if len(valid_pairs):\n",
    "        common_pair = valid_pairs.value_counts([\"brand_new\",\"model_new\"]).idxmax()\n",
    "    else:\n",
    "        common_pair = bm.groupby([\"brand\",\"model\"]).size().sort_values(ascending=False).index[0]\n",
    "    mask_both = (df[\"brand_new\"]==\"\") & (df[\"model_new\"]==\"\")\n",
    "    df.loc[mask_both, [\"brand_new\",\"model_new\"]] = common_pair\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- exemplo ---\n",
    "df_new = clean(train, brand_model_dic)\n",
    "# df_new.to_csv(\"clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b940cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(\"clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19caae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "focus       2865\n",
      "c class     2159\n",
      "fiesta      1929\n",
      "golf        1410\n",
      "corsa       1007\n",
      "            ... \n",
      "terracan       1\n",
      "rapi           1\n",
      "k              1\n",
      "camr           1\n",
      "cascada        1\n",
      "Name: count, Length: 269, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7000b9b5",
   "metadata": {},
   "source": [
    "### year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb4eedb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2022.87800554, 2017.        , 2016.        , 2019.        ,\n",
       "       2018.        , 2011.        , 2015.        ,           nan,\n",
       "       2023.26798867, 2014.        , 2020.        , 2013.        ,\n",
       "       2010.        , 2024.12175905, 2008.        , 2012.        ,\n",
       "       2010.56500919, 2010.37154646, 2011.21085349, 2009.        ,\n",
       "       2022.69668507, 2007.        , 2023.38982198, 2023.97731126,\n",
       "       2023.36707842, 2004.        , 2010.26863473, 2010.67696784,\n",
       "       2023.1169636 , 2002.        , 2023.60527574, 2012.69574039,\n",
       "       2006.        , 2000.        , 2003.        , 1997.        ,\n",
       "       2011.11118842, 2009.81675711, 2010.7464032 , 2001.        ,\n",
       "       1999.        , 1998.        , 2005.        , 1991.        ,\n",
       "       1996.        ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17ba99f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022 2017 2016 2019 2018 2011 2015 9999 2023 2014 2020 2013 2010 2024\n",
      " 2008 2012 2009 2007 2004 2002 2006 2000 2003 1997 2001 1999 1998 2005\n",
      " 1991 1996]\n",
      "Brand              object\n",
      "model              object\n",
      "year                int64\n",
      "transmission       object\n",
      "mileage           float64\n",
      "fuelType           object\n",
      "tax               float64\n",
      "mpg               float64\n",
      "engineSize        float64\n",
      "paintQuality%     float64\n",
      "previousOwners    float64\n",
      "hasDamage         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#por agora nulos ficom com 9999\n",
    "df[\"year\"] = df[\"year\"].fillna(9999)\n",
    "\n",
    "# Ficar só com a parte inteira e converter para int\n",
    "df[\"year\"] = df[\"year\"].astype(float).astype(int)\n",
    "\n",
    "print(df[\"year\"].unique())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ffeae",
   "metadata": {},
   "source": [
    "### transmission       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a0534be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Automatic', 'Semi-Auto', 'Manual', 'unknow', 'Manua', 'automatic',\n",
       "       nan, 'semi-auto', 'MANUAL', 'Semi-Aut', 'unknown', 'emi-Auto',\n",
       "       'utomatic', 'SEMI-AUTO', 'anual', 'Automati', 'manual',\n",
       "       'AUTOMATIC', ' Manual ', ' Manual', 'UNKNOWN', 'anua', 'AUTOMATI',\n",
       "       'nknown', 'MANUA', 'Other', ' MANUAL ', 'manual ', 'manua',\n",
       "       'UTOMATIC', 'automati', 'utomati', 'ANUAL', 'emi-auto', 'EMI-AUTO',\n",
       "       'SEMI-AUT', 'Manual ', ' manual ', 'emi-Aut'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"transmission\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d6de570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['automatic', 'semi-auto', 'manual', 'unknow', 'manua', nan,\n",
       "       'semi-aut', 'unknown', 'emi-auto', 'utomatic', 'anual', 'automati',\n",
       "       'anua', 'nknown', 'other', 'utomati', 'emi-aut'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"transmission\"] = df[\"transmission\"].str.lower().str.strip()\n",
    "df[\"transmission\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d216b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Automatic' 'Semi-Auto' 'Manual' 'Unknown' nan 'Other']\n"
     ]
    }
   ],
   "source": [
    "df[\"transmission\"] = df[\"transmission\"].str.lower().str.strip()\n",
    "\n",
    "# Criar mapeamento só para marcas que já vi no teu print\n",
    "trans_map = {\n",
    "    \"automatic\": \"Automatic\", \"utomatic\": \"Automatic\", \"automati\": \"Automatic\",\"utomati\": \"Automatic\",\n",
    "    \"semi-auto\": \"Semi-Auto\", \"semi-aut\": \"Semi-Auto\",\"emi-auto\": \"Semi-Auto\", \"emi-aut\": \"Semi-Auto\",\n",
    "    \"manual\": \"Manual\", \"manua\": \"Manual\",\"anual\": \"Manual\", \"anua\": \"Manual\",\n",
    "    \"unknow\": \"Unknown\", \"unknown\": \"Unknown\", \"nknown\": \"Unknown\",\n",
    "    \"other\": \"Other\"\n",
    "}\n",
    "\n",
    "# Substituir se existir no dicionário\n",
    "df[\"transmission\"] = df[\"transmission\"].map(lambda x: trans_map.get(x, x))\n",
    "\n",
    "# Ver marcas únicas já limpas\n",
    "print(df[\"transmission\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ded272",
   "metadata": {},
   "source": [
    "### mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d5df64ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 30700.        , -48190.65567291,  36792.        , ...,\n",
       "        27575.        ,   8297.        ,  11071.        ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"mileage\"].unique()\n",
    "#tem de ser numero e tem de ser poitivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fbaec2",
   "metadata": {},
   "source": [
    "### fuelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19b52423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['petrol', 'Petrol', 'Diesel', 'Diese', 'Hybrid', 'iesel', 'Petro',\n",
       "       'hybrid', 'etrol', 'DIESEL', nan, 'PETROL', 'diesel', 'Other',\n",
       "       'iese', 'diese', 'etro', 'petro', 'HYBRID', 'Hybri', 'ther',\n",
       "       'ETROL', 'ybrid', 'IESEL', 'DIESE', 'PETRO', 'hybri', 'other',\n",
       "       'Othe', 'Electric'], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"fuelType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57d17a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Petrol' 'Diesel' 'Hybrid' 'Unknown' 'Other' 'Electric']\n"
     ]
    }
   ],
   "source": [
    "# Normalizar (minúsculas + remover espaços)\n",
    "df[\"fuelType\"] = df[\"fuelType\"].str.lower().str.strip()\n",
    "\n",
    "# Mapeamento só com o que foi encontrado\n",
    "fuel_map = {\n",
    "    # Petrol\n",
    "    \"petrol\": \"Petrol\", \"petro\": \"Petrol\", \"etro\": \"Petrol\",\"etrol\": \"Petrol\",\n",
    "    \n",
    "    # Diesel\n",
    "    \"diesel\": \"Diesel\", \"diese\": \"Diesel\", \"iesel\": \"Diesel\",\"iese\": \"Diesel\",\n",
    "    \n",
    "    # Hybrid\n",
    "    \"hybrid\": \"Hybrid\", \"hybri\": \"Hybrid\",\"ybrid\": \"Hybrid\",\n",
    "    \n",
    "    # Electric\n",
    "    \"electric\": \"Electric\",\n",
    "    \n",
    "    # Other\n",
    "    \"other\": \"Other\", \"othe\": \"Other\", \"ther\": \"Other\"\n",
    "}\n",
    "\n",
    "# Aplicar mapeamento\n",
    "df[\"fuelType\"] = df[\"fuelType\"].map(lambda x: fuel_map.get(x, x))\n",
    "\n",
    "# Substituir NaN por \"Unknown\"\n",
    "df[\"fuelType\"] = df[\"fuelType\"].fillna(\"Unknown\")\n",
    "\n",
    "# Ver categorias finais\n",
    "print(df[\"fuelType\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd02fb",
   "metadata": {},
   "source": [
    "### tax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562458a5",
   "metadata": {},
   "source": [
    "### mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a76a037",
   "metadata": {},
   "source": [
    "### engineSize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b1d94",
   "metadata": {},
   "source": [
    "### paintQuality%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04dd0ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 61.        ,  60.        ,  94.        ,  77.        ,\n",
       "        45.        ,  64.        ,  50.        ,  71.        ,\n",
       "        99.        ,  73.        ,  78.        ,  40.        ,\n",
       "        35.        ,  76.        ,  53.        ,  90.        ,\n",
       "                nan,  42.        ,  70.        ,  75.        ,\n",
       "        79.        ,  98.        ,  62.        ,  88.        ,\n",
       "        59.        ,  97.        ,  85.        ,  89.        ,\n",
       "        92.        ,  63.        ,  36.        ,  56.        ,\n",
       "        54.        ,  52.        ,  66.        ,  80.        ,\n",
       "        91.        ,  31.        ,  37.        ,  67.        ,\n",
       "        30.        ,  84.        ,  69.        ,  55.        ,\n",
       "        57.        ,  48.        ,  44.        ,  39.        ,\n",
       "        82.        ,  34.        ,  33.        , 125.10995148,\n",
       "         3.20741784,  65.        ,  86.        ,  74.        ,\n",
       "       125.00377307,  87.        ,  72.        ,  93.        ,\n",
       "        46.        ,  38.        ,  47.        ,  49.        ,\n",
       "        83.        ,  96.        ,  51.        ,  32.        ,\n",
       "        81.        ,  43.        ,  95.        ,  41.        ,\n",
       "        68.        ,  58.        ,   3.17268306,   1.76947364,\n",
       "         3.22574362, 125.30194543, 125.5694986 ,   3.1152953 ,\n",
       "         3.25476013,   3.14037046, 125.59430832, 125.36650692,\n",
       "         2.72515272, 125.18872876,   1.63891309, 125.20203342,\n",
       "       125.4535988 ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"paintQuality%\"].unique()\n",
    "#decidir o que fazer com os superior a 100. 1) truncar para 100. 2) apagar e preencher com a mediana 3)apagar e knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc9e1e",
   "metadata": {},
   "source": [
    "### previousOwners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d6a8870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.        ,  2.        ,  1.        ,  4.        ,  0.        ,\n",
       "               nan, -2.34565   ,  6.25823052,  6.23017958,  6.25837066,\n",
       "       -2.29943868,  6.21772443, -2.33512284,  6.2482512 ,  6.23308217,\n",
       "       -2.33744529,  6.24583495,  6.24177863, -2.33936045, -2.31225953,\n",
       "       -2.34030622, -2.31733109, -2.34010209,  6.22789796])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"previousOwners\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e371d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   3    2    1    4    0 9999    6]\n",
      "Brand              object\n",
      "model              object\n",
      "year                int64\n",
      "transmission       object\n",
      "mileage           float64\n",
      "fuelType           object\n",
      "tax               float64\n",
      "mpg               float64\n",
      "engineSize        float64\n",
      "paintQuality%     float64\n",
      "previousOwners      int64\n",
      "hasDamage         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Substituir NaN por 9999 (ou outro valor que prefiras, ex: 0)\n",
    "df[\"previousOwners\"] = df[\"previousOwners\"].fillna(9999)\n",
    "\n",
    "# Converter para inteiro\n",
    "df[\"previousOwners\"] = df[\"previousOwners\"].astype(float).astype(int)\n",
    "\n",
    "# Tornar valores negativos em positivos\n",
    "df[\"previousOwners\"] = df[\"previousOwners\"].abs()\n",
    "\n",
    "print(df[\"previousOwners\"].unique())\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c7623",
   "metadata": {},
   "source": [
    "### hasDamage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ed0e861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., nan])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"hasDamage\"].unique()\n",
    "#para apagar a variavel que nao tem nada de jeito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d32a1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., nan])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"hasDamage\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a37a688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer exploração da media "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef1b619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = train[train[\"hasDamage\"]== 0]\n",
    "train_nan = train[~(train[\"hasDamage\"] == 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2d7f4a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14698.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0[\"price\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ead3628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14798.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nan[\"price\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "878d1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#como nao houve diferença na media então tiramos a variavel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fall2526",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
